{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-8(i)-Keras-metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash-Mahadeshwar/Deep-Learning-with-Keras/blob/master/Lab_8(i)_Keras_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJdKMnxbQ35X",
        "colab_type": "text"
      },
      "source": [
        "#Usage of metrics\n",
        "\n",
        "A metric is a function that is used to judge the performance of your model. Metric functions are to be supplied in the metrics parameter when a model is compiled.\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='sgd',\n",
        "              metrics=['mae', 'acc'])\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='sgd',\n",
        "              metrics=[metrics.mae, metrics.categorical_accuracy])\n",
        "```\n",
        "\n",
        "A metric function is similar to a loss function, except that the results from evaluating a metric are not used when training the model. You may use any of the loss functions as a metric function.\n",
        "\n",
        "You can either pass the name of an existing metric, or pass a Theano/TensorFlow symbolic function (see Custom metrics).\n",
        "\n",
        "##Arguments\n",
        "1. y_true: True labels. Theano/TensorFlow tensor.\n",
        "2. y_pred: Predictions. Theano/TensorFlow tensor of the same shape as y_true.\n",
        "\n",
        "##Returns\n",
        "\n",
        "1. Single tensor value representing the mean of the output array across all datapoints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_roXIFgkRIRf",
        "colab_type": "text"
      },
      "source": [
        "#Accuracy\n",
        "keras.metrics.accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXkjmUIiROMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3040579-1a89-4cda-a64f-93c7e70032b0"
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='elu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.2909 - acc: 0.9122 - val_loss: 0.1547 - val_acc: 0.9524\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.1202 - acc: 0.9634 - val_loss: 0.1147 - val_acc: 0.9626\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0835 - acc: 0.9742 - val_loss: 0.0941 - val_acc: 0.9699\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0631 - acc: 0.9800 - val_loss: 0.0964 - val_acc: 0.9736\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 1s 25us/step - loss: 0.0510 - acc: 0.9836 - val_loss: 0.0795 - val_acc: 0.9774\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0395 - acc: 0.9871 - val_loss: 0.0805 - val_acc: 0.9777\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0345 - acc: 0.9889 - val_loss: 0.0847 - val_acc: 0.9773\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0272 - acc: 0.9908 - val_loss: 0.0827 - val_acc: 0.9787\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0225 - acc: 0.9922 - val_loss: 0.0946 - val_acc: 0.9775\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0190 - acc: 0.9937 - val_loss: 0.0885 - val_acc: 0.9800\n",
            "Test loss: 0.08847574553290924\n",
            "Test accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTHlkI9CRX4M",
        "colab_type": "text"
      },
      "source": [
        "#binary_accuracy\n",
        "\n",
        "keras.metrics.binary_accuracy(y_true, y_pred, threshold=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yJ88okURbcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "fa922b7a-22ca-4a7b-fed5-b0b37afa61e7"
      },
      "source": [
        "# Compile model using binary_accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['binary_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0188 - binary_accuracy: 0.9987 - val_loss: 0.0987 - val_binary_accuracy: 0.9956\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0159 - binary_accuracy: 0.9990 - val_loss: 0.1109 - val_binary_accuracy: 0.9956\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0130 - binary_accuracy: 0.9992 - val_loss: 0.1015 - val_binary_accuracy: 0.9960\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0112 - binary_accuracy: 0.9993 - val_loss: 0.1005 - val_binary_accuracy: 0.9965\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0111 - binary_accuracy: 0.9993 - val_loss: 0.1075 - val_binary_accuracy: 0.9960\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0088 - binary_accuracy: 0.9994 - val_loss: 0.1123 - val_binary_accuracy: 0.9961\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0098 - binary_accuracy: 0.9994 - val_loss: 0.1275 - val_binary_accuracy: 0.9957\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0083 - binary_accuracy: 0.9995 - val_loss: 0.1027 - val_binary_accuracy: 0.9966\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0077 - binary_accuracy: 0.9995 - val_loss: 0.1078 - val_binary_accuracy: 0.9965\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0077 - binary_accuracy: 0.9995 - val_loss: 0.1313 - val_binary_accuracy: 0.9962\n",
            "Test loss: 0.13134842750381923\n",
            "Test accuracy: 0.9962299951553345\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i34lhk62Rr00",
        "colab_type": "text"
      },
      "source": [
        "#categorical_accuracy\n",
        "\n",
        "keras.metrics.categorical_accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8yiFITLRut3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "6233af8e-9666-4e7f-a605-8df942762d91"
      },
      "source": [
        "# Compile model using categorical_accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0079 - categorical_accuracy: 0.9973 - val_loss: 0.1081 - val_categorical_accuracy: 0.9838\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0070 - categorical_accuracy: 0.9978 - val_loss: 0.1157 - val_categorical_accuracy: 0.9817\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0063 - categorical_accuracy: 0.9982 - val_loss: 0.1248 - val_categorical_accuracy: 0.9813\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0061 - categorical_accuracy: 0.9980 - val_loss: 0.1372 - val_categorical_accuracy: 0.9803\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0060 - categorical_accuracy: 0.9981 - val_loss: 0.1388 - val_categorical_accuracy: 0.9810\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0060 - categorical_accuracy: 0.9984 - val_loss: 0.1424 - val_categorical_accuracy: 0.9813\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0043 - categorical_accuracy: 0.9987 - val_loss: 0.1578 - val_categorical_accuracy: 0.9790\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0047 - categorical_accuracy: 0.9987 - val_loss: 0.1414 - val_categorical_accuracy: 0.9818\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0054 - categorical_accuracy: 0.9986 - val_loss: 0.1479 - val_categorical_accuracy: 0.9807\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0047 - categorical_accuracy: 0.9988 - val_loss: 0.1486 - val_categorical_accuracy: 0.9810\n",
            "Test loss: 0.14863256499225438\n",
            "Test accuracy: 0.981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2C271EXSqnV",
        "colab_type": "text"
      },
      "source": [
        "#top_k_categorical_accuracy\n",
        "\n",
        "keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70hdQEGZSsKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "16e6c0b3-8c46-437c-85d1-157bf696e610"
      },
      "source": [
        "# Compile model using categorical_accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0042 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1406 - val_top_k_categorical_accuracy: 0.9997\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0042 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1525 - val_top_k_categorical_accuracy: 0.9999\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0047 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1516 - val_top_k_categorical_accuracy: 0.9997\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0041 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1333 - val_top_k_categorical_accuracy: 0.9998\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0042 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1445 - val_top_k_categorical_accuracy: 0.9999\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0034 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1518 - val_top_k_categorical_accuracy: 0.9995\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0032 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1511 - val_top_k_categorical_accuracy: 0.9995\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0030 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1510 - val_top_k_categorical_accuracy: 0.9996\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0026 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1545 - val_top_k_categorical_accuracy: 0.9998\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0029 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1564 - val_top_k_categorical_accuracy: 0.9997\n",
            "Test loss: 0.15643760927909744\n",
            "Test accuracy: 0.9997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WTKc7LCR22d",
        "colab_type": "text"
      },
      "source": [
        "#sparse_categorical_accuracy\n",
        "\n",
        "keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpEKVQaQR-iq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e6e930d-d010-4194-b417-6b92b81ba7da"
      },
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# prepare sequence\n",
        "X = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "y = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
        "# train model\n",
        "history = model.fit(X, y, epochs=400, batch_size=len(X), verbose=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            " - 0s - loss: 0.7335 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 2/400\n",
            " - 0s - loss: 0.7329 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 3/400\n",
            " - 0s - loss: 0.7324 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 4/400\n",
            " - 0s - loss: 0.7318 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 5/400\n",
            " - 0s - loss: 0.7313 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 6/400\n",
            " - 0s - loss: 0.7308 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 7/400\n",
            " - 0s - loss: 0.7302 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 8/400\n",
            " - 0s - loss: 0.7297 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 9/400\n",
            " - 0s - loss: 0.7291 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 10/400\n",
            " - 0s - loss: 0.7286 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 11/400\n",
            " - 0s - loss: 0.7281 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 12/400\n",
            " - 0s - loss: 0.7276 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 13/400\n",
            " - 0s - loss: 0.7271 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 14/400\n",
            " - 0s - loss: 0.7266 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 15/400\n",
            " - 0s - loss: 0.7261 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 16/400\n",
            " - 0s - loss: 0.7256 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 17/400\n",
            " - 0s - loss: 0.7251 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 18/400\n",
            " - 0s - loss: 0.7246 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 19/400\n",
            " - 0s - loss: 0.7241 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 20/400\n",
            " - 0s - loss: 0.7236 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 21/400\n",
            " - 0s - loss: 0.7231 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 22/400\n",
            " - 0s - loss: 0.7226 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 23/400\n",
            " - 0s - loss: 0.7222 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 24/400\n",
            " - 0s - loss: 0.7217 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 25/400\n",
            " - 0s - loss: 0.7212 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 26/400\n",
            " - 0s - loss: 0.7208 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 27/400\n",
            " - 0s - loss: 0.7203 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 28/400\n",
            " - 0s - loss: 0.7199 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 29/400\n",
            " - 0s - loss: 0.7194 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 30/400\n",
            " - 0s - loss: 0.7190 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 31/400\n",
            " - 0s - loss: 0.7185 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 32/400\n",
            " - 0s - loss: 0.7181 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 33/400\n",
            " - 0s - loss: 0.7177 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 34/400\n",
            " - 0s - loss: 0.7172 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 35/400\n",
            " - 0s - loss: 0.7168 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 36/400\n",
            " - 0s - loss: 0.7164 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 37/400\n",
            " - 0s - loss: 0.7160 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 38/400\n",
            " - 0s - loss: 0.7155 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 39/400\n",
            " - 0s - loss: 0.7151 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 40/400\n",
            " - 0s - loss: 0.7147 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 41/400\n",
            " - 0s - loss: 0.7143 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 42/400\n",
            " - 0s - loss: 0.7139 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 43/400\n",
            " - 0s - loss: 0.7135 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 44/400\n",
            " - 0s - loss: 0.7131 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 45/400\n",
            " - 0s - loss: 0.7127 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 46/400\n",
            " - 0s - loss: 0.7123 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 47/400\n",
            " - 0s - loss: 0.7119 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 48/400\n",
            " - 0s - loss: 0.7115 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 49/400\n",
            " - 0s - loss: 0.7112 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 50/400\n",
            " - 0s - loss: 0.7108 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 51/400\n",
            " - 0s - loss: 0.7104 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 52/400\n",
            " - 0s - loss: 0.7100 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 53/400\n",
            " - 0s - loss: 0.7096 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 54/400\n",
            " - 0s - loss: 0.7093 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 55/400\n",
            " - 0s - loss: 0.7089 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 56/400\n",
            " - 0s - loss: 0.7085 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 57/400\n",
            " - 0s - loss: 0.7081 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 58/400\n",
            " - 0s - loss: 0.7078 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 59/400\n",
            " - 0s - loss: 0.7074 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 60/400\n",
            " - 0s - loss: 0.7070 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 61/400\n",
            " - 0s - loss: 0.7067 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 62/400\n",
            " - 0s - loss: 0.7063 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 63/400\n",
            " - 0s - loss: 0.7059 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 64/400\n",
            " - 0s - loss: 0.7056 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 65/400\n",
            " - 0s - loss: 0.7052 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 66/400\n",
            " - 0s - loss: 0.7048 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 67/400\n",
            " - 0s - loss: 0.7045 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 68/400\n",
            " - 0s - loss: 0.7041 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 69/400\n",
            " - 0s - loss: 0.7038 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 70/400\n",
            " - 0s - loss: 0.7034 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 71/400\n",
            " - 0s - loss: 0.7030 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 72/400\n",
            " - 0s - loss: 0.7027 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 73/400\n",
            " - 0s - loss: 0.7023 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 74/400\n",
            " - 0s - loss: 0.7020 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 75/400\n",
            " - 0s - loss: 0.7016 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 76/400\n",
            " - 0s - loss: 0.7013 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 77/400\n",
            " - 0s - loss: 0.7009 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 78/400\n",
            " - 0s - loss: 0.7005 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 79/400\n",
            " - 0s - loss: 0.7002 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 80/400\n",
            " - 0s - loss: 0.6998 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 81/400\n",
            " - 0s - loss: 0.6995 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 82/400\n",
            " - 0s - loss: 0.6991 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 83/400\n",
            " - 0s - loss: 0.6988 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 84/400\n",
            " - 0s - loss: 0.6984 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 85/400\n",
            " - 0s - loss: 0.6980 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 86/400\n",
            " - 0s - loss: 0.6977 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 87/400\n",
            " - 0s - loss: 0.6973 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 88/400\n",
            " - 0s - loss: 0.6970 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 89/400\n",
            " - 0s - loss: 0.6966 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 90/400\n",
            " - 0s - loss: 0.6963 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 91/400\n",
            " - 0s - loss: 0.6959 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 92/400\n",
            " - 0s - loss: 0.6955 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 93/400\n",
            " - 0s - loss: 0.6952 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 94/400\n",
            " - 0s - loss: 0.6948 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 95/400\n",
            " - 0s - loss: 0.6945 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 96/400\n",
            " - 0s - loss: 0.6941 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 97/400\n",
            " - 0s - loss: 0.6938 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 98/400\n",
            " - 0s - loss: 0.6934 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 99/400\n",
            " - 0s - loss: 0.6930 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 100/400\n",
            " - 0s - loss: 0.6927 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 101/400\n",
            " - 0s - loss: 0.6923 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 102/400\n",
            " - 0s - loss: 0.6920 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 103/400\n",
            " - 0s - loss: 0.6916 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 104/400\n",
            " - 0s - loss: 0.6912 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 105/400\n",
            " - 0s - loss: 0.6909 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 106/400\n",
            " - 0s - loss: 0.6905 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 107/400\n",
            " - 0s - loss: 0.6902 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 108/400\n",
            " - 0s - loss: 0.6898 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 109/400\n",
            " - 0s - loss: 0.6895 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 110/400\n",
            " - 0s - loss: 0.6891 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 111/400\n",
            " - 0s - loss: 0.6887 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 112/400\n",
            " - 0s - loss: 0.6884 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 113/400\n",
            " - 0s - loss: 0.6880 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 114/400\n",
            " - 0s - loss: 0.6877 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 115/400\n",
            " - 0s - loss: 0.6873 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 116/400\n",
            " - 0s - loss: 0.6869 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 117/400\n",
            " - 0s - loss: 0.6866 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 118/400\n",
            " - 0s - loss: 0.6862 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 119/400\n",
            " - 0s - loss: 0.6859 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 120/400\n",
            " - 0s - loss: 0.6855 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 121/400\n",
            " - 0s - loss: 0.6852 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 122/400\n",
            " - 0s - loss: 0.6848 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 123/400\n",
            " - 0s - loss: 0.6844 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 124/400\n",
            " - 0s - loss: 0.6841 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 125/400\n",
            " - 0s - loss: 0.6837 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 126/400\n",
            " - 0s - loss: 0.6834 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 127/400\n",
            " - 0s - loss: 0.6830 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 128/400\n",
            " - 0s - loss: 0.6826 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 129/400\n",
            " - 0s - loss: 0.6823 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 130/400\n",
            " - 0s - loss: 0.6819 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 131/400\n",
            " - 0s - loss: 0.6816 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 132/400\n",
            " - 0s - loss: 0.6812 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 133/400\n",
            " - 0s - loss: 0.6808 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 134/400\n",
            " - 0s - loss: 0.6805 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 135/400\n",
            " - 0s - loss: 0.6801 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 136/400\n",
            " - 0s - loss: 0.6798 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 137/400\n",
            " - 0s - loss: 0.6794 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 138/400\n",
            " - 0s - loss: 0.6790 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 139/400\n",
            " - 0s - loss: 0.6787 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 140/400\n",
            " - 0s - loss: 0.6783 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 141/400\n",
            " - 0s - loss: 0.6780 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 142/400\n",
            " - 0s - loss: 0.6776 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 143/400\n",
            " - 0s - loss: 0.6772 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 144/400\n",
            " - 0s - loss: 0.6769 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 145/400\n",
            " - 0s - loss: 0.6765 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 146/400\n",
            " - 0s - loss: 0.6762 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 147/400\n",
            " - 0s - loss: 0.6758 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 148/400\n",
            " - 0s - loss: 0.6755 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 149/400\n",
            " - 0s - loss: 0.6751 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 150/400\n",
            " - 0s - loss: 0.6747 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 151/400\n",
            " - 0s - loss: 0.6744 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 152/400\n",
            " - 0s - loss: 0.6740 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 153/400\n",
            " - 0s - loss: 0.6737 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 154/400\n",
            " - 0s - loss: 0.6733 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 155/400\n",
            " - 0s - loss: 0.6729 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 156/400\n",
            " - 0s - loss: 0.6726 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 157/400\n",
            " - 0s - loss: 0.6722 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 158/400\n",
            " - 0s - loss: 0.6719 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 159/400\n",
            " - 0s - loss: 0.6715 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 160/400\n",
            " - 0s - loss: 0.6711 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 161/400\n",
            " - 0s - loss: 0.6708 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 162/400\n",
            " - 0s - loss: 0.6704 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 163/400\n",
            " - 0s - loss: 0.6701 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 164/400\n",
            " - 0s - loss: 0.6697 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 165/400\n",
            " - 0s - loss: 0.6693 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 166/400\n",
            " - 0s - loss: 0.6690 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 167/400\n",
            " - 0s - loss: 0.6686 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 168/400\n",
            " - 0s - loss: 0.6683 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 169/400\n",
            " - 0s - loss: 0.6679 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 170/400\n",
            " - 0s - loss: 0.6676 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 171/400\n",
            " - 0s - loss: 0.6672 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 172/400\n",
            " - 0s - loss: 0.6668 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 173/400\n",
            " - 0s - loss: 0.6665 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 174/400\n",
            " - 0s - loss: 0.6661 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 175/400\n",
            " - 0s - loss: 0.6658 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 176/400\n",
            " - 0s - loss: 0.6654 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 177/400\n",
            " - 0s - loss: 0.6650 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 178/400\n",
            " - 0s - loss: 0.6647 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 179/400\n",
            " - 0s - loss: 0.6643 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 180/400\n",
            " - 0s - loss: 0.6640 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 181/400\n",
            " - 0s - loss: 0.6636 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 182/400\n",
            " - 0s - loss: 0.6633 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 183/400\n",
            " - 0s - loss: 0.6629 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 184/400\n",
            " - 0s - loss: 0.6625 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 185/400\n",
            " - 0s - loss: 0.6622 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 186/400\n",
            " - 0s - loss: 0.6618 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 187/400\n",
            " - 0s - loss: 0.6615 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 188/400\n",
            " - 0s - loss: 0.6611 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 189/400\n",
            " - 0s - loss: 0.6607 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 190/400\n",
            " - 0s - loss: 0.6604 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 191/400\n",
            " - 0s - loss: 0.6600 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 192/400\n",
            " - 0s - loss: 0.6597 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 193/400\n",
            " - 0s - loss: 0.6593 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 194/400\n",
            " - 0s - loss: 0.6590 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 195/400\n",
            " - 0s - loss: 0.6586 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 196/400\n",
            " - 0s - loss: 0.6582 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 197/400\n",
            " - 0s - loss: 0.6579 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 198/400\n",
            " - 0s - loss: 0.6575 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 199/400\n",
            " - 0s - loss: 0.6572 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 200/400\n",
            " - 0s - loss: 0.6568 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 201/400\n",
            " - 0s - loss: 0.6565 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 202/400\n",
            " - 0s - loss: 0.6561 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 203/400\n",
            " - 0s - loss: 0.6557 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 204/400\n",
            " - 0s - loss: 0.6554 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 205/400\n",
            " - 0s - loss: 0.6550 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 206/400\n",
            " - 0s - loss: 0.6547 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 207/400\n",
            " - 0s - loss: 0.6543 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 208/400\n",
            " - 0s - loss: 0.6540 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 209/400\n",
            " - 0s - loss: 0.6536 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 210/400\n",
            " - 0s - loss: 0.6532 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 211/400\n",
            " - 0s - loss: 0.6529 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 212/400\n",
            " - 0s - loss: 0.6525 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 213/400\n",
            " - 0s - loss: 0.6522 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 214/400\n",
            " - 0s - loss: 0.6518 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 215/400\n",
            " - 0s - loss: 0.6515 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 216/400\n",
            " - 0s - loss: 0.6511 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 217/400\n",
            " - 0s - loss: 0.6507 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 218/400\n",
            " - 0s - loss: 0.6504 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 219/400\n",
            " - 0s - loss: 0.6500 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 220/400\n",
            " - 0s - loss: 0.6497 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 221/400\n",
            " - 0s - loss: 0.6493 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 222/400\n",
            " - 0s - loss: 0.6490 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 223/400\n",
            " - 0s - loss: 0.6486 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 224/400\n",
            " - 0s - loss: 0.6482 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 225/400\n",
            " - 0s - loss: 0.6479 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 226/400\n",
            " - 0s - loss: 0.6475 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 227/400\n",
            " - 0s - loss: 0.6472 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 228/400\n",
            " - 0s - loss: 0.6468 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 229/400\n",
            " - 0s - loss: 0.6465 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 230/400\n",
            " - 0s - loss: 0.6461 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 231/400\n",
            " - 0s - loss: 0.6458 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 232/400\n",
            " - 0s - loss: 0.6454 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 233/400\n",
            " - 0s - loss: 0.6450 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 234/400\n",
            " - 0s - loss: 0.6447 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 235/400\n",
            " - 0s - loss: 0.6443 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 236/400\n",
            " - 0s - loss: 0.6440 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 237/400\n",
            " - 0s - loss: 0.6436 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 238/400\n",
            " - 0s - loss: 0.6433 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 239/400\n",
            " - 0s - loss: 0.6429 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 240/400\n",
            " - 0s - loss: 0.6426 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 241/400\n",
            " - 0s - loss: 0.6422 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 242/400\n",
            " - 0s - loss: 0.6419 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 243/400\n",
            " - 0s - loss: 0.6415 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 244/400\n",
            " - 0s - loss: 0.6411 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 245/400\n",
            " - 0s - loss: 0.6408 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 246/400\n",
            " - 0s - loss: 0.6404 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 247/400\n",
            " - 0s - loss: 0.6401 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 248/400\n",
            " - 0s - loss: 0.6397 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 249/400\n",
            " - 0s - loss: 0.6394 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 250/400\n",
            " - 0s - loss: 0.6390 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 251/400\n",
            " - 0s - loss: 0.6387 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 252/400\n",
            " - 0s - loss: 0.6383 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 253/400\n",
            " - 0s - loss: 0.6380 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 254/400\n",
            " - 0s - loss: 0.6376 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 255/400\n",
            " - 0s - loss: 0.6372 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 256/400\n",
            " - 0s - loss: 0.6369 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 257/400\n",
            " - 0s - loss: 0.6365 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 258/400\n",
            " - 0s - loss: 0.6362 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 259/400\n",
            " - 0s - loss: 0.6358 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 260/400\n",
            " - 0s - loss: 0.6355 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 261/400\n",
            " - 0s - loss: 0.6351 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 262/400\n",
            " - 0s - loss: 0.6348 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 263/400\n",
            " - 0s - loss: 0.6344 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 264/400\n",
            " - 0s - loss: 0.6341 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 265/400\n",
            " - 0s - loss: 0.6337 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 266/400\n",
            " - 0s - loss: 0.6334 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 267/400\n",
            " - 0s - loss: 0.6330 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 268/400\n",
            " - 0s - loss: 0.6326 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 269/400\n",
            " - 0s - loss: 0.6323 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 270/400\n",
            " - 0s - loss: 0.6319 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 271/400\n",
            " - 0s - loss: 0.6316 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 272/400\n",
            " - 0s - loss: 0.6312 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 273/400\n",
            " - 0s - loss: 0.6309 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 274/400\n",
            " - 0s - loss: 0.6305 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 275/400\n",
            " - 0s - loss: 0.6302 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 276/400\n",
            " - 0s - loss: 0.6298 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 277/400\n",
            " - 0s - loss: 0.6295 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 278/400\n",
            " - 0s - loss: 0.6291 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 279/400\n",
            " - 0s - loss: 0.6288 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 280/400\n",
            " - 0s - loss: 0.6284 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 281/400\n",
            " - 0s - loss: 0.6281 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 282/400\n",
            " - 0s - loss: 0.6277 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 283/400\n",
            " - 0s - loss: 0.6274 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 284/400\n",
            " - 0s - loss: 0.6270 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 285/400\n",
            " - 0s - loss: 0.6267 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 286/400\n",
            " - 0s - loss: 0.6263 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 287/400\n",
            " - 0s - loss: 0.6260 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 288/400\n",
            " - 0s - loss: 0.6256 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 289/400\n",
            " - 0s - loss: 0.6252 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 290/400\n",
            " - 0s - loss: 0.6249 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 291/400\n",
            " - 0s - loss: 0.6245 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 292/400\n",
            " - 0s - loss: 0.6242 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 293/400\n",
            " - 0s - loss: 0.6238 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 294/400\n",
            " - 0s - loss: 0.6235 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 295/400\n",
            " - 0s - loss: 0.6231 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 296/400\n",
            " - 0s - loss: 0.6228 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 297/400\n",
            " - 0s - loss: 0.6224 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 298/400\n",
            " - 0s - loss: 0.6221 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 299/400\n",
            " - 0s - loss: 0.6217 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 300/400\n",
            " - 0s - loss: 0.6214 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 301/400\n",
            " - 0s - loss: 0.6210 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 302/400\n",
            " - 0s - loss: 0.6207 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 303/400\n",
            " - 0s - loss: 0.6203 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 304/400\n",
            " - 0s - loss: 0.6200 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 305/400\n",
            " - 0s - loss: 0.6196 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 306/400\n",
            " - 0s - loss: 0.6193 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 307/400\n",
            " - 0s - loss: 0.6189 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 308/400\n",
            " - 0s - loss: 0.6186 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 309/400\n",
            " - 0s - loss: 0.6182 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 310/400\n",
            " - 0s - loss: 0.6179 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 311/400\n",
            " - 0s - loss: 0.6175 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 312/400\n",
            " - 0s - loss: 0.6172 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 313/400\n",
            " - 0s - loss: 0.6168 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 314/400\n",
            " - 0s - loss: 0.6165 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 315/400\n",
            " - 0s - loss: 0.6161 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 316/400\n",
            " - 0s - loss: 0.6158 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 317/400\n",
            " - 0s - loss: 0.6154 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 318/400\n",
            " - 0s - loss: 0.6151 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 319/400\n",
            " - 0s - loss: 0.6147 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 320/400\n",
            " - 0s - loss: 0.6144 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 321/400\n",
            " - 0s - loss: 0.6140 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 322/400\n",
            " - 0s - loss: 0.6137 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 323/400\n",
            " - 0s - loss: 0.6133 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 324/400\n",
            " - 0s - loss: 0.6130 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 325/400\n",
            " - 0s - loss: 0.6126 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 326/400\n",
            " - 0s - loss: 0.6123 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 327/400\n",
            " - 0s - loss: 0.6119 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 328/400\n",
            " - 0s - loss: 0.6116 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 329/400\n",
            " - 0s - loss: 0.6112 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 330/400\n",
            " - 0s - loss: 0.6109 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 331/400\n",
            " - 0s - loss: 0.6105 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 332/400\n",
            " - 0s - loss: 0.6102 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 333/400\n",
            " - 0s - loss: 0.6098 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 334/400\n",
            " - 0s - loss: 0.6095 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 335/400\n",
            " - 0s - loss: 0.6091 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 336/400\n",
            " - 0s - loss: 0.6088 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 337/400\n",
            " - 0s - loss: 0.6084 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 338/400\n",
            " - 0s - loss: 0.6081 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 339/400\n",
            " - 0s - loss: 0.6077 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 340/400\n",
            " - 0s - loss: 0.6074 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 341/400\n",
            " - 0s - loss: 0.6070 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 342/400\n",
            " - 0s - loss: 0.6067 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 343/400\n",
            " - 0s - loss: 0.6064 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 344/400\n",
            " - 0s - loss: 0.6060 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 345/400\n",
            " - 0s - loss: 0.6057 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 346/400\n",
            " - 0s - loss: 0.6053 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 347/400\n",
            " - 0s - loss: 0.6050 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 348/400\n",
            " - 0s - loss: 0.6046 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 349/400\n",
            " - 0s - loss: 0.6043 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 350/400\n",
            " - 0s - loss: 0.6039 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 351/400\n",
            " - 0s - loss: 0.6036 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 352/400\n",
            " - 0s - loss: 0.6032 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 353/400\n",
            " - 0s - loss: 0.6029 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 354/400\n",
            " - 0s - loss: 0.6025 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 355/400\n",
            " - 0s - loss: 0.6022 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 356/400\n",
            " - 0s - loss: 0.6018 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 357/400\n",
            " - 0s - loss: 0.6015 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 358/400\n",
            " - 0s - loss: 0.6011 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 359/400\n",
            " - 0s - loss: 0.6008 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 360/400\n",
            " - 0s - loss: 0.6004 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 361/400\n",
            " - 0s - loss: 0.6001 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 362/400\n",
            " - 0s - loss: 0.5997 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 363/400\n",
            " - 0s - loss: 0.5994 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 364/400\n",
            " - 0s - loss: 0.5991 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 365/400\n",
            " - 0s - loss: 0.5987 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 366/400\n",
            " - 0s - loss: 0.5984 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 367/400\n",
            " - 0s - loss: 0.5980 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 368/400\n",
            " - 0s - loss: 0.5977 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 369/400\n",
            " - 0s - loss: 0.5973 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 370/400\n",
            " - 0s - loss: 0.5970 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 371/400\n",
            " - 0s - loss: 0.5966 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 372/400\n",
            " - 0s - loss: 0.5963 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 373/400\n",
            " - 0s - loss: 0.5959 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 374/400\n",
            " - 0s - loss: 0.5956 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 375/400\n",
            " - 0s - loss: 0.5952 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 376/400\n",
            " - 0s - loss: 0.5949 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 377/400\n",
            " - 0s - loss: 0.5946 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 378/400\n",
            " - 0s - loss: 0.5942 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 379/400\n",
            " - 0s - loss: 0.5939 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 380/400\n",
            " - 0s - loss: 0.5935 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 381/400\n",
            " - 0s - loss: 0.5932 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 382/400\n",
            " - 0s - loss: 0.5928 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 383/400\n",
            " - 0s - loss: 0.5925 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 384/400\n",
            " - 0s - loss: 0.5921 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 385/400\n",
            " - 0s - loss: 0.5918 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 386/400\n",
            " - 0s - loss: 0.5914 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 387/400\n",
            " - 0s - loss: 0.5911 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 388/400\n",
            " - 0s - loss: 0.5908 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 389/400\n",
            " - 0s - loss: 0.5904 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 390/400\n",
            " - 0s - loss: 0.5901 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 391/400\n",
            " - 0s - loss: 0.5897 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 392/400\n",
            " - 0s - loss: 0.5894 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 393/400\n",
            " - 0s - loss: 0.5890 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 394/400\n",
            " - 0s - loss: 0.5887 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 395/400\n",
            " - 0s - loss: 0.5883 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 396/400\n",
            " - 0s - loss: 0.5880 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 397/400\n",
            " - 0s - loss: 0.5876 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 398/400\n",
            " - 0s - loss: 0.5873 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 399/400\n",
            " - 0s - loss: 0.5870 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 400/400\n",
            " - 0s - loss: 0.5866 - sparse_categorical_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHCFoRZKUdki",
        "colab_type": "text"
      },
      "source": [
        "#sparse_top_k_categorical_accuracy\n",
        "\n",
        "keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8FWdLp_UfPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c6242694-6c86-44c2-ffdb-4936b0f3f40c"
      },
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# prepare sequence\n",
        "X = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "y = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['sparse_top_k_categorical_accuracy'])\n",
        "# train model\n",
        "history = model.fit(X, y, epochs=400, batch_size=len(X), verbose=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            " - 0s - loss: 0.6384 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 2/400\n",
            " - 0s - loss: 0.6380 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 3/400\n",
            " - 0s - loss: 0.6377 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 4/400\n",
            " - 0s - loss: 0.6373 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 5/400\n",
            " - 0s - loss: 0.6370 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 6/400\n",
            " - 0s - loss: 0.6366 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 7/400\n",
            " - 0s - loss: 0.6363 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 8/400\n",
            " - 0s - loss: 0.6359 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 9/400\n",
            " - 0s - loss: 0.6356 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 10/400\n",
            " - 0s - loss: 0.6352 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 11/400\n",
            " - 0s - loss: 0.6349 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 12/400\n",
            " - 0s - loss: 0.6345 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 13/400\n",
            " - 0s - loss: 0.6342 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 14/400\n",
            " - 0s - loss: 0.6338 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 15/400\n",
            " - 0s - loss: 0.6335 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 16/400\n",
            " - 0s - loss: 0.6331 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 17/400\n",
            " - 0s - loss: 0.6328 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 18/400\n",
            " - 0s - loss: 0.6324 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 19/400\n",
            " - 0s - loss: 0.6321 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 20/400\n",
            " - 0s - loss: 0.6317 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 21/400\n",
            " - 0s - loss: 0.6314 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 22/400\n",
            " - 0s - loss: 0.6310 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 23/400\n",
            " - 0s - loss: 0.6307 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 24/400\n",
            " - 0s - loss: 0.6303 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 25/400\n",
            " - 0s - loss: 0.6300 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 26/400\n",
            " - 0s - loss: 0.6297 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 27/400\n",
            " - 0s - loss: 0.6293 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 28/400\n",
            " - 0s - loss: 0.6290 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 29/400\n",
            " - 0s - loss: 0.6286 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 30/400\n",
            " - 0s - loss: 0.6283 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 31/400\n",
            " - 0s - loss: 0.6279 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 32/400\n",
            " - 0s - loss: 0.6276 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 33/400\n",
            " - 0s - loss: 0.6272 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 34/400\n",
            " - 0s - loss: 0.6269 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 35/400\n",
            " - 0s - loss: 0.6265 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 36/400\n",
            " - 0s - loss: 0.6262 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 37/400\n",
            " - 0s - loss: 0.6259 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 38/400\n",
            " - 0s - loss: 0.6255 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 39/400\n",
            " - 0s - loss: 0.6252 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 40/400\n",
            " - 0s - loss: 0.6248 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 41/400\n",
            " - 0s - loss: 0.6245 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 42/400\n",
            " - 0s - loss: 0.6241 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 43/400\n",
            " - 0s - loss: 0.6238 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 44/400\n",
            " - 0s - loss: 0.6234 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 45/400\n",
            " - 0s - loss: 0.6231 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 46/400\n",
            " - 0s - loss: 0.6227 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 47/400\n",
            " - 0s - loss: 0.6224 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 48/400\n",
            " - 0s - loss: 0.6220 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 49/400\n",
            " - 0s - loss: 0.6217 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 50/400\n",
            " - 0s - loss: 0.6213 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 51/400\n",
            " - 0s - loss: 0.6210 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 52/400\n",
            " - 0s - loss: 0.6206 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 53/400\n",
            " - 0s - loss: 0.6203 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 54/400\n",
            " - 0s - loss: 0.6199 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 55/400\n",
            " - 0s - loss: 0.6196 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 56/400\n",
            " - 0s - loss: 0.6192 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 57/400\n",
            " - 0s - loss: 0.6189 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 58/400\n",
            " - 0s - loss: 0.6185 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 59/400\n",
            " - 0s - loss: 0.6182 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 60/400\n",
            " - 0s - loss: 0.6178 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 61/400\n",
            " - 0s - loss: 0.6175 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 62/400\n",
            " - 0s - loss: 0.6171 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 63/400\n",
            " - 0s - loss: 0.6168 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 64/400\n",
            " - 0s - loss: 0.6164 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 65/400\n",
            " - 0s - loss: 0.6161 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 66/400\n",
            " - 0s - loss: 0.6157 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 67/400\n",
            " - 0s - loss: 0.6154 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 68/400\n",
            " - 0s - loss: 0.6150 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 69/400\n",
            " - 0s - loss: 0.6147 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 70/400\n",
            " - 0s - loss: 0.6143 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 71/400\n",
            " - 0s - loss: 0.6140 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 72/400\n",
            " - 0s - loss: 0.6136 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 73/400\n",
            " - 0s - loss: 0.6133 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 74/400\n",
            " - 0s - loss: 0.6129 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 75/400\n",
            " - 0s - loss: 0.6126 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 76/400\n",
            " - 0s - loss: 0.6122 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 77/400\n",
            " - 0s - loss: 0.6119 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 78/400\n",
            " - 0s - loss: 0.6115 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 79/400\n",
            " - 0s - loss: 0.6111 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 80/400\n",
            " - 0s - loss: 0.6108 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 81/400\n",
            " - 0s - loss: 0.6104 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 82/400\n",
            " - 0s - loss: 0.6101 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 83/400\n",
            " - 0s - loss: 0.6097 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 84/400\n",
            " - 0s - loss: 0.6094 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 85/400\n",
            " - 0s - loss: 0.6090 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 86/400\n",
            " - 0s - loss: 0.6087 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 87/400\n",
            " - 0s - loss: 0.6083 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 88/400\n",
            " - 0s - loss: 0.6079 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 89/400\n",
            " - 0s - loss: 0.6076 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 90/400\n",
            " - 0s - loss: 0.6072 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 91/400\n",
            " - 0s - loss: 0.6069 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 92/400\n",
            " - 0s - loss: 0.6065 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 93/400\n",
            " - 0s - loss: 0.6061 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 94/400\n",
            " - 0s - loss: 0.6058 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 95/400\n",
            " - 0s - loss: 0.6054 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 96/400\n",
            " - 0s - loss: 0.6051 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 97/400\n",
            " - 0s - loss: 0.6047 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 98/400\n",
            " - 0s - loss: 0.6043 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 99/400\n",
            " - 0s - loss: 0.6040 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 100/400\n",
            " - 0s - loss: 0.6036 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 101/400\n",
            " - 0s - loss: 0.6033 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 102/400\n",
            " - 0s - loss: 0.6029 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 103/400\n",
            " - 0s - loss: 0.6025 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 104/400\n",
            " - 0s - loss: 0.6022 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 105/400\n",
            " - 0s - loss: 0.6018 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 106/400\n",
            " - 0s - loss: 0.6015 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 107/400\n",
            " - 0s - loss: 0.6011 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 108/400\n",
            " - 0s - loss: 0.6007 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 109/400\n",
            " - 0s - loss: 0.6004 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 110/400\n",
            " - 0s - loss: 0.6000 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 111/400\n",
            " - 0s - loss: 0.5996 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 112/400\n",
            " - 0s - loss: 0.5993 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 113/400\n",
            " - 0s - loss: 0.5989 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 114/400\n",
            " - 0s - loss: 0.5985 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 115/400\n",
            " - 0s - loss: 0.5982 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 116/400\n",
            " - 0s - loss: 0.5978 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 117/400\n",
            " - 0s - loss: 0.5974 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 118/400\n",
            " - 0s - loss: 0.5971 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 119/400\n",
            " - 0s - loss: 0.5967 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 120/400\n",
            " - 0s - loss: 0.5963 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 121/400\n",
            " - 0s - loss: 0.5960 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 122/400\n",
            " - 0s - loss: 0.5956 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 123/400\n",
            " - 0s - loss: 0.5952 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 124/400\n",
            " - 0s - loss: 0.5949 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 125/400\n",
            " - 0s - loss: 0.5945 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 126/400\n",
            " - 0s - loss: 0.5941 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 127/400\n",
            " - 0s - loss: 0.5938 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 128/400\n",
            " - 0s - loss: 0.5934 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 129/400\n",
            " - 0s - loss: 0.5930 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 130/400\n",
            " - 0s - loss: 0.5927 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 131/400\n",
            " - 0s - loss: 0.5923 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 132/400\n",
            " - 0s - loss: 0.5919 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 133/400\n",
            " - 0s - loss: 0.5916 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 134/400\n",
            " - 0s - loss: 0.5912 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 135/400\n",
            " - 0s - loss: 0.5908 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 136/400\n",
            " - 0s - loss: 0.5904 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 137/400\n",
            " - 0s - loss: 0.5901 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 138/400\n",
            " - 0s - loss: 0.5897 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 139/400\n",
            " - 0s - loss: 0.5893 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 140/400\n",
            " - 0s - loss: 0.5889 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 141/400\n",
            " - 0s - loss: 0.5886 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 142/400\n",
            " - 0s - loss: 0.5882 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 143/400\n",
            " - 0s - loss: 0.5878 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 144/400\n",
            " - 0s - loss: 0.5875 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 145/400\n",
            " - 0s - loss: 0.5871 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 146/400\n",
            " - 0s - loss: 0.5867 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 147/400\n",
            " - 0s - loss: 0.5863 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 148/400\n",
            " - 0s - loss: 0.5859 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 149/400\n",
            " - 0s - loss: 0.5856 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 150/400\n",
            " - 0s - loss: 0.5852 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 151/400\n",
            " - 0s - loss: 0.5848 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 152/400\n",
            " - 0s - loss: 0.5844 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 153/400\n",
            " - 0s - loss: 0.5841 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 154/400\n",
            " - 0s - loss: 0.5837 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 155/400\n",
            " - 0s - loss: 0.5833 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 156/400\n",
            " - 0s - loss: 0.5829 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 157/400\n",
            " - 0s - loss: 0.5826 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 158/400\n",
            " - 0s - loss: 0.5822 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 159/400\n",
            " - 0s - loss: 0.5818 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 160/400\n",
            " - 0s - loss: 0.5814 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 161/400\n",
            " - 0s - loss: 0.5810 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 162/400\n",
            " - 0s - loss: 0.5807 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 163/400\n",
            " - 0s - loss: 0.5803 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 164/400\n",
            " - 0s - loss: 0.5799 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 165/400\n",
            " - 0s - loss: 0.5795 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 166/400\n",
            " - 0s - loss: 0.5791 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 167/400\n",
            " - 0s - loss: 0.5788 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 168/400\n",
            " - 0s - loss: 0.5784 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 169/400\n",
            " - 0s - loss: 0.5780 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 170/400\n",
            " - 0s - loss: 0.5776 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 171/400\n",
            " - 0s - loss: 0.5772 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 172/400\n",
            " - 0s - loss: 0.5768 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 173/400\n",
            " - 0s - loss: 0.5765 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 174/400\n",
            " - 0s - loss: 0.5761 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 175/400\n",
            " - 0s - loss: 0.5757 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 176/400\n",
            " - 0s - loss: 0.5753 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 177/400\n",
            " - 0s - loss: 0.5749 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 178/400\n",
            " - 0s - loss: 0.5745 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 179/400\n",
            " - 0s - loss: 0.5741 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 180/400\n",
            " - 0s - loss: 0.5738 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 181/400\n",
            " - 0s - loss: 0.5734 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 182/400\n",
            " - 0s - loss: 0.5730 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 183/400\n",
            " - 0s - loss: 0.5726 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 184/400\n",
            " - 0s - loss: 0.5722 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 185/400\n",
            " - 0s - loss: 0.5718 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 186/400\n",
            " - 0s - loss: 0.5714 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 187/400\n",
            " - 0s - loss: 0.5710 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 188/400\n",
            " - 0s - loss: 0.5707 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 189/400\n",
            " - 0s - loss: 0.5703 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 190/400\n",
            " - 0s - loss: 0.5699 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 191/400\n",
            " - 0s - loss: 0.5695 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 192/400\n",
            " - 0s - loss: 0.5691 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 193/400\n",
            " - 0s - loss: 0.5687 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 194/400\n",
            " - 0s - loss: 0.5683 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 195/400\n",
            " - 0s - loss: 0.5679 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 196/400\n",
            " - 0s - loss: 0.5675 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 197/400\n",
            " - 0s - loss: 0.5672 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 198/400\n",
            " - 0s - loss: 0.5668 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 199/400\n",
            " - 0s - loss: 0.5664 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 200/400\n",
            " - 0s - loss: 0.5660 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 201/400\n",
            " - 0s - loss: 0.5656 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 202/400\n",
            " - 0s - loss: 0.5652 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 203/400\n",
            " - 0s - loss: 0.5648 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 204/400\n",
            " - 0s - loss: 0.5644 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 205/400\n",
            " - 0s - loss: 0.5640 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 206/400\n",
            " - 0s - loss: 0.5636 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 207/400\n",
            " - 0s - loss: 0.5632 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 208/400\n",
            " - 0s - loss: 0.5628 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 209/400\n",
            " - 0s - loss: 0.5624 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 210/400\n",
            " - 0s - loss: 0.5620 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 211/400\n",
            " - 0s - loss: 0.5616 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 212/400\n",
            " - 0s - loss: 0.5612 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 213/400\n",
            " - 0s - loss: 0.5609 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 214/400\n",
            " - 0s - loss: 0.5605 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 215/400\n",
            " - 0s - loss: 0.5601 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 216/400\n",
            " - 0s - loss: 0.5597 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 217/400\n",
            " - 0s - loss: 0.5593 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 218/400\n",
            " - 0s - loss: 0.5589 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 219/400\n",
            " - 0s - loss: 0.5585 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 220/400\n",
            " - 0s - loss: 0.5581 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 221/400\n",
            " - 0s - loss: 0.5577 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 222/400\n",
            " - 0s - loss: 0.5573 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 223/400\n",
            " - 0s - loss: 0.5569 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 224/400\n",
            " - 0s - loss: 0.5565 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 225/400\n",
            " - 0s - loss: 0.5561 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 226/400\n",
            " - 0s - loss: 0.5557 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 227/400\n",
            " - 0s - loss: 0.5553 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 228/400\n",
            " - 0s - loss: 0.5549 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 229/400\n",
            " - 0s - loss: 0.5545 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 230/400\n",
            " - 0s - loss: 0.5541 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 231/400\n",
            " - 0s - loss: 0.5537 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 232/400\n",
            " - 0s - loss: 0.5533 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 233/400\n",
            " - 0s - loss: 0.5529 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 234/400\n",
            " - 0s - loss: 0.5525 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 235/400\n",
            " - 0s - loss: 0.5521 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 236/400\n",
            " - 0s - loss: 0.5517 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 237/400\n",
            " - 0s - loss: 0.5513 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 238/400\n",
            " - 0s - loss: 0.5509 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 239/400\n",
            " - 0s - loss: 0.5505 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 240/400\n",
            " - 0s - loss: 0.5501 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 241/400\n",
            " - 0s - loss: 0.5497 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 242/400\n",
            " - 0s - loss: 0.5493 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 243/400\n",
            " - 0s - loss: 0.5489 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 244/400\n",
            " - 0s - loss: 0.5485 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 245/400\n",
            " - 0s - loss: 0.5480 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 246/400\n",
            " - 0s - loss: 0.5476 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 247/400\n",
            " - 0s - loss: 0.5472 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 248/400\n",
            " - 0s - loss: 0.5468 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 249/400\n",
            " - 0s - loss: 0.5464 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 250/400\n",
            " - 0s - loss: 0.5460 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 251/400\n",
            " - 0s - loss: 0.5456 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 252/400\n",
            " - 0s - loss: 0.5452 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 253/400\n",
            " - 0s - loss: 0.5448 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 254/400\n",
            " - 0s - loss: 0.5444 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 255/400\n",
            " - 0s - loss: 0.5440 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 256/400\n",
            " - 0s - loss: 0.5436 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 257/400\n",
            " - 0s - loss: 0.5432 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 258/400\n",
            " - 0s - loss: 0.5428 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 259/400\n",
            " - 0s - loss: 0.5424 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 260/400\n",
            " - 0s - loss: 0.5420 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 261/400\n",
            " - 0s - loss: 0.5415 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 262/400\n",
            " - 0s - loss: 0.5411 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 263/400\n",
            " - 0s - loss: 0.5407 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 264/400\n",
            " - 0s - loss: 0.5403 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 265/400\n",
            " - 0s - loss: 0.5399 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 266/400\n",
            " - 0s - loss: 0.5395 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 267/400\n",
            " - 0s - loss: 0.5391 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 268/400\n",
            " - 0s - loss: 0.5387 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 269/400\n",
            " - 0s - loss: 0.5383 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 270/400\n",
            " - 0s - loss: 0.5379 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 271/400\n",
            " - 0s - loss: 0.5375 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 272/400\n",
            " - 0s - loss: 0.5371 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 273/400\n",
            " - 0s - loss: 0.5366 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 274/400\n",
            " - 0s - loss: 0.5362 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 275/400\n",
            " - 0s - loss: 0.5358 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 276/400\n",
            " - 0s - loss: 0.5354 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 277/400\n",
            " - 0s - loss: 0.5350 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 278/400\n",
            " - 0s - loss: 0.5346 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 279/400\n",
            " - 0s - loss: 0.5342 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 280/400\n",
            " - 0s - loss: 0.5338 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 281/400\n",
            " - 0s - loss: 0.5334 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 282/400\n",
            " - 0s - loss: 0.5329 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 283/400\n",
            " - 0s - loss: 0.5325 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 284/400\n",
            " - 0s - loss: 0.5321 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 285/400\n",
            " - 0s - loss: 0.5317 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 286/400\n",
            " - 0s - loss: 0.5313 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 287/400\n",
            " - 0s - loss: 0.5309 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 288/400\n",
            " - 0s - loss: 0.5305 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 289/400\n",
            " - 0s - loss: 0.5301 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 290/400\n",
            " - 0s - loss: 0.5296 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 291/400\n",
            " - 0s - loss: 0.5292 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 292/400\n",
            " - 0s - loss: 0.5288 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 293/400\n",
            " - 0s - loss: 0.5284 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 294/400\n",
            " - 0s - loss: 0.5280 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 295/400\n",
            " - 0s - loss: 0.5276 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 296/400\n",
            " - 0s - loss: 0.5272 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 297/400\n",
            " - 0s - loss: 0.5267 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 298/400\n",
            " - 0s - loss: 0.5263 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 299/400\n",
            " - 0s - loss: 0.5259 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 300/400\n",
            " - 0s - loss: 0.5255 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 301/400\n",
            " - 0s - loss: 0.5251 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 302/400\n",
            " - 0s - loss: 0.5247 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 303/400\n",
            " - 0s - loss: 0.5243 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 304/400\n",
            " - 0s - loss: 0.5238 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 305/400\n",
            " - 0s - loss: 0.5234 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 306/400\n",
            " - 0s - loss: 0.5230 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 307/400\n",
            " - 0s - loss: 0.5226 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 308/400\n",
            " - 0s - loss: 0.5222 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 309/400\n",
            " - 0s - loss: 0.5218 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 310/400\n",
            " - 0s - loss: 0.5213 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 311/400\n",
            " - 0s - loss: 0.5209 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 312/400\n",
            " - 0s - loss: 0.5205 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 313/400\n",
            " - 0s - loss: 0.5201 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 314/400\n",
            " - 0s - loss: 0.5197 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 315/400\n",
            " - 0s - loss: 0.5193 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 316/400\n",
            " - 0s - loss: 0.5189 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 317/400\n",
            " - 0s - loss: 0.5184 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 318/400\n",
            " - 0s - loss: 0.5180 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 319/400\n",
            " - 0s - loss: 0.5176 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 320/400\n",
            " - 0s - loss: 0.5172 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 321/400\n",
            " - 0s - loss: 0.5168 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 322/400\n",
            " - 0s - loss: 0.5163 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 323/400\n",
            " - 0s - loss: 0.5159 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 324/400\n",
            " - 0s - loss: 0.5155 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 325/400\n",
            " - 0s - loss: 0.5151 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 326/400\n",
            " - 0s - loss: 0.5147 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 327/400\n",
            " - 0s - loss: 0.5143 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 328/400\n",
            " - 0s - loss: 0.5138 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 329/400\n",
            " - 0s - loss: 0.5134 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 330/400\n",
            " - 0s - loss: 0.5130 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 331/400\n",
            " - 0s - loss: 0.5126 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 332/400\n",
            " - 0s - loss: 0.5122 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 333/400\n",
            " - 0s - loss: 0.5118 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 334/400\n",
            " - 0s - loss: 0.5113 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 335/400\n",
            " - 0s - loss: 0.5109 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 336/400\n",
            " - 0s - loss: 0.5105 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 337/400\n",
            " - 0s - loss: 0.5101 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 338/400\n",
            " - 0s - loss: 0.5097 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 339/400\n",
            " - 0s - loss: 0.5092 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 340/400\n",
            " - 0s - loss: 0.5088 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 341/400\n",
            " - 0s - loss: 0.5084 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 342/400\n",
            " - 0s - loss: 0.5080 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 343/400\n",
            " - 0s - loss: 0.5076 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 344/400\n",
            " - 0s - loss: 0.5071 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 345/400\n",
            " - 0s - loss: 0.5067 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 346/400\n",
            " - 0s - loss: 0.5063 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 347/400\n",
            " - 0s - loss: 0.5059 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 348/400\n",
            " - 0s - loss: 0.5055 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 349/400\n",
            " - 0s - loss: 0.5051 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 350/400\n",
            " - 0s - loss: 0.5046 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 351/400\n",
            " - 0s - loss: 0.5042 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 352/400\n",
            " - 0s - loss: 0.5038 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 353/400\n",
            " - 0s - loss: 0.5034 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 354/400\n",
            " - 0s - loss: 0.5030 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 355/400\n",
            " - 0s - loss: 0.5025 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 356/400\n",
            " - 0s - loss: 0.5021 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 357/400\n",
            " - 0s - loss: 0.5017 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 358/400\n",
            " - 0s - loss: 0.5013 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 359/400\n",
            " - 0s - loss: 0.5009 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 360/400\n",
            " - 0s - loss: 0.5004 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 361/400\n",
            " - 0s - loss: 0.5000 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 362/400\n",
            " - 0s - loss: 0.4996 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 363/400\n",
            " - 0s - loss: 0.4992 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 364/400\n",
            " - 0s - loss: 0.4988 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 365/400\n",
            " - 0s - loss: 0.4983 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 366/400\n",
            " - 0s - loss: 0.4979 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 367/400\n",
            " - 0s - loss: 0.4975 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 368/400\n",
            " - 0s - loss: 0.4971 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 369/400\n",
            " - 0s - loss: 0.4967 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 370/400\n",
            " - 0s - loss: 0.4962 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 371/400\n",
            " - 0s - loss: 0.4958 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 372/400\n",
            " - 0s - loss: 0.4954 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 373/400\n",
            " - 0s - loss: 0.4950 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 374/400\n",
            " - 0s - loss: 0.4946 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 375/400\n",
            " - 0s - loss: 0.4941 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 376/400\n",
            " - 0s - loss: 0.4937 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 377/400\n",
            " - 0s - loss: 0.4933 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 378/400\n",
            " - 0s - loss: 0.4929 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 379/400\n",
            " - 0s - loss: 0.4925 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 380/400\n",
            " - 0s - loss: 0.4920 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 381/400\n",
            " - 0s - loss: 0.4916 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 382/400\n",
            " - 0s - loss: 0.4912 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 383/400\n",
            " - 0s - loss: 0.4908 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 384/400\n",
            " - 0s - loss: 0.4904 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 385/400\n",
            " - 0s - loss: 0.4899 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 386/400\n",
            " - 0s - loss: 0.4895 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 387/400\n",
            " - 0s - loss: 0.4891 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 388/400\n",
            " - 0s - loss: 0.4887 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 389/400\n",
            " - 0s - loss: 0.4883 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 390/400\n",
            " - 0s - loss: 0.4878 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 391/400\n",
            " - 0s - loss: 0.4874 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 392/400\n",
            " - 0s - loss: 0.4870 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 393/400\n",
            " - 0s - loss: 0.4866 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 394/400\n",
            " - 0s - loss: 0.4862 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 395/400\n",
            " - 0s - loss: 0.4857 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 396/400\n",
            " - 0s - loss: 0.4853 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 397/400\n",
            " - 0s - loss: 0.4849 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 398/400\n",
            " - 0s - loss: 0.4845 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 399/400\n",
            " - 0s - loss: 0.4841 - sparse_top_k_categorical_accuracy: 0.5000\n",
            "Epoch 400/400\n",
            " - 0s - loss: 0.4836 - sparse_top_k_categorical_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MljdGHXMUwYr",
        "colab_type": "text"
      },
      "source": [
        "#cosine_proximity\n",
        "\n",
        "keras.metrics.cosine_proximity(y_true, y_pred, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfLN9tE6UyQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f2b1d11-363b-4385-8791-7ecea6d63366"
      },
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from matplotlib import pyplot\n",
        "# prepare sequence\n",
        "X = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
        "y = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['cosine_proximity'])\n",
        "# train model\n",
        "history = model.fit(X, y, epochs=400, batch_size=len(X), verbose=2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            " - 0s - loss: 0.8159 - cosine_proximity: -5.0000e-01\n",
            "Epoch 2/400\n",
            " - 0s - loss: 0.8153 - cosine_proximity: -5.0000e-01\n",
            "Epoch 3/400\n",
            " - 0s - loss: 0.8147 - cosine_proximity: -5.0000e-01\n",
            "Epoch 4/400\n",
            " - 0s - loss: 0.8139 - cosine_proximity: -5.0000e-01\n",
            "Epoch 5/400\n",
            " - 0s - loss: 0.8132 - cosine_proximity: -5.0000e-01\n",
            "Epoch 6/400\n",
            " - 0s - loss: 0.8124 - cosine_proximity: -5.0000e-01\n",
            "Epoch 7/400\n",
            " - 0s - loss: 0.8117 - cosine_proximity: -5.0000e-01\n",
            "Epoch 8/400\n",
            " - 0s - loss: 0.8109 - cosine_proximity: -5.0000e-01\n",
            "Epoch 9/400\n",
            " - 0s - loss: 0.8102 - cosine_proximity: -5.0000e-01\n",
            "Epoch 10/400\n",
            " - 0s - loss: 0.8094 - cosine_proximity: -5.0000e-01\n",
            "Epoch 11/400\n",
            " - 0s - loss: 0.8087 - cosine_proximity: -5.0000e-01\n",
            "Epoch 12/400\n",
            " - 0s - loss: 0.8079 - cosine_proximity: -5.0000e-01\n",
            "Epoch 13/400\n",
            " - 0s - loss: 0.8072 - cosine_proximity: -5.0000e-01\n",
            "Epoch 14/400\n",
            " - 0s - loss: 0.8064 - cosine_proximity: -5.0000e-01\n",
            "Epoch 15/400\n",
            " - 0s - loss: 0.8057 - cosine_proximity: -5.0000e-01\n",
            "Epoch 16/400\n",
            " - 0s - loss: 0.8050 - cosine_proximity: -5.0000e-01\n",
            "Epoch 17/400\n",
            " - 0s - loss: 0.8042 - cosine_proximity: -5.0000e-01\n",
            "Epoch 18/400\n",
            " - 0s - loss: 0.8035 - cosine_proximity: -5.0000e-01\n",
            "Epoch 19/400\n",
            " - 0s - loss: 0.8028 - cosine_proximity: -5.0000e-01\n",
            "Epoch 20/400\n",
            " - 0s - loss: 0.8021 - cosine_proximity: -5.0000e-01\n",
            "Epoch 21/400\n",
            " - 0s - loss: 0.8014 - cosine_proximity: -5.0000e-01\n",
            "Epoch 22/400\n",
            " - 0s - loss: 0.8007 - cosine_proximity: -5.0000e-01\n",
            "Epoch 23/400\n",
            " - 0s - loss: 0.8000 - cosine_proximity: -5.0000e-01\n",
            "Epoch 24/400\n",
            " - 0s - loss: 0.7993 - cosine_proximity: -5.0000e-01\n",
            "Epoch 25/400\n",
            " - 0s - loss: 0.7987 - cosine_proximity: -5.0000e-01\n",
            "Epoch 26/400\n",
            " - 0s - loss: 0.7980 - cosine_proximity: -5.0000e-01\n",
            "Epoch 27/400\n",
            " - 0s - loss: 0.7973 - cosine_proximity: -5.0000e-01\n",
            "Epoch 28/400\n",
            " - 0s - loss: 0.7967 - cosine_proximity: -5.0000e-01\n",
            "Epoch 29/400\n",
            " - 0s - loss: 0.7960 - cosine_proximity: -5.0000e-01\n",
            "Epoch 30/400\n",
            " - 0s - loss: 0.7954 - cosine_proximity: -5.0000e-01\n",
            "Epoch 31/400\n",
            " - 0s - loss: 0.7947 - cosine_proximity: -5.0000e-01\n",
            "Epoch 32/400\n",
            " - 0s - loss: 0.7941 - cosine_proximity: -5.0000e-01\n",
            "Epoch 33/400\n",
            " - 0s - loss: 0.7935 - cosine_proximity: -5.0000e-01\n",
            "Epoch 34/400\n",
            " - 0s - loss: 0.7929 - cosine_proximity: -5.0000e-01\n",
            "Epoch 35/400\n",
            " - 0s - loss: 0.7923 - cosine_proximity: -5.0000e-01\n",
            "Epoch 36/400\n",
            " - 0s - loss: 0.7916 - cosine_proximity: -5.0000e-01\n",
            "Epoch 37/400\n",
            " - 0s - loss: 0.7910 - cosine_proximity: -5.0000e-01\n",
            "Epoch 38/400\n",
            " - 0s - loss: 0.7904 - cosine_proximity: -5.0000e-01\n",
            "Epoch 39/400\n",
            " - 0s - loss: 0.7899 - cosine_proximity: -5.0000e-01\n",
            "Epoch 40/400\n",
            " - 0s - loss: 0.7893 - cosine_proximity: -5.0000e-01\n",
            "Epoch 41/400\n",
            " - 0s - loss: 0.7887 - cosine_proximity: -5.0000e-01\n",
            "Epoch 42/400\n",
            " - 0s - loss: 0.7881 - cosine_proximity: -5.0000e-01\n",
            "Epoch 43/400\n",
            " - 0s - loss: 0.7876 - cosine_proximity: -5.0000e-01\n",
            "Epoch 44/400\n",
            " - 0s - loss: 0.7870 - cosine_proximity: -5.0000e-01\n",
            "Epoch 45/400\n",
            " - 0s - loss: 0.7864 - cosine_proximity: -5.0000e-01\n",
            "Epoch 46/400\n",
            " - 0s - loss: 0.7859 - cosine_proximity: -5.0000e-01\n",
            "Epoch 47/400\n",
            " - 0s - loss: 0.7853 - cosine_proximity: -5.0000e-01\n",
            "Epoch 48/400\n",
            " - 0s - loss: 0.7848 - cosine_proximity: -5.0000e-01\n",
            "Epoch 49/400\n",
            " - 0s - loss: 0.7842 - cosine_proximity: -5.0000e-01\n",
            "Epoch 50/400\n",
            " - 0s - loss: 0.7837 - cosine_proximity: -5.0000e-01\n",
            "Epoch 51/400\n",
            " - 0s - loss: 0.7832 - cosine_proximity: -5.0000e-01\n",
            "Epoch 52/400\n",
            " - 0s - loss: 0.7827 - cosine_proximity: -5.0000e-01\n",
            "Epoch 53/400\n",
            " - 0s - loss: 0.7821 - cosine_proximity: -5.0000e-01\n",
            "Epoch 54/400\n",
            " - 0s - loss: 0.7816 - cosine_proximity: -5.0000e-01\n",
            "Epoch 55/400\n",
            " - 0s - loss: 0.7811 - cosine_proximity: -5.0000e-01\n",
            "Epoch 56/400\n",
            " - 0s - loss: 0.7806 - cosine_proximity: -5.0000e-01\n",
            "Epoch 57/400\n",
            " - 0s - loss: 0.7801 - cosine_proximity: -5.0000e-01\n",
            "Epoch 58/400\n",
            " - 0s - loss: 0.7796 - cosine_proximity: -5.0000e-01\n",
            "Epoch 59/400\n",
            " - 0s - loss: 0.7791 - cosine_proximity: -5.0000e-01\n",
            "Epoch 60/400\n",
            " - 0s - loss: 0.7786 - cosine_proximity: -5.0000e-01\n",
            "Epoch 61/400\n",
            " - 0s - loss: 0.7781 - cosine_proximity: -5.0000e-01\n",
            "Epoch 62/400\n",
            " - 0s - loss: 0.7777 - cosine_proximity: -5.0000e-01\n",
            "Epoch 63/400\n",
            " - 0s - loss: 0.7772 - cosine_proximity: -5.0000e-01\n",
            "Epoch 64/400\n",
            " - 0s - loss: 0.7767 - cosine_proximity: -5.0000e-01\n",
            "Epoch 65/400\n",
            " - 0s - loss: 0.7762 - cosine_proximity: -5.0000e-01\n",
            "Epoch 66/400\n",
            " - 0s - loss: 0.7758 - cosine_proximity: -5.0000e-01\n",
            "Epoch 67/400\n",
            " - 0s - loss: 0.7753 - cosine_proximity: -5.0000e-01\n",
            "Epoch 68/400\n",
            " - 0s - loss: 0.7749 - cosine_proximity: -5.0000e-01\n",
            "Epoch 69/400\n",
            " - 0s - loss: 0.7744 - cosine_proximity: -5.0000e-01\n",
            "Epoch 70/400\n",
            " - 0s - loss: 0.7740 - cosine_proximity: -5.0000e-01\n",
            "Epoch 71/400\n",
            " - 0s - loss: 0.7735 - cosine_proximity: -5.0000e-01\n",
            "Epoch 72/400\n",
            " - 0s - loss: 0.7731 - cosine_proximity: -5.0000e-01\n",
            "Epoch 73/400\n",
            " - 0s - loss: 0.7726 - cosine_proximity: -5.0000e-01\n",
            "Epoch 74/400\n",
            " - 0s - loss: 0.7722 - cosine_proximity: -5.0000e-01\n",
            "Epoch 75/400\n",
            " - 0s - loss: 0.7718 - cosine_proximity: -5.0000e-01\n",
            "Epoch 76/400\n",
            " - 0s - loss: 0.7713 - cosine_proximity: -5.0000e-01\n",
            "Epoch 77/400\n",
            " - 0s - loss: 0.7709 - cosine_proximity: -5.0000e-01\n",
            "Epoch 78/400\n",
            " - 0s - loss: 0.7705 - cosine_proximity: -5.0000e-01\n",
            "Epoch 79/400\n",
            " - 0s - loss: 0.7701 - cosine_proximity: -5.0000e-01\n",
            "Epoch 80/400\n",
            " - 0s - loss: 0.7696 - cosine_proximity: -5.0000e-01\n",
            "Epoch 81/400\n",
            " - 0s - loss: 0.7692 - cosine_proximity: -5.0000e-01\n",
            "Epoch 82/400\n",
            " - 0s - loss: 0.7688 - cosine_proximity: -5.0000e-01\n",
            "Epoch 83/400\n",
            " - 0s - loss: 0.7684 - cosine_proximity: -5.0000e-01\n",
            "Epoch 84/400\n",
            " - 0s - loss: 0.7680 - cosine_proximity: -5.0000e-01\n",
            "Epoch 85/400\n",
            " - 0s - loss: 0.7676 - cosine_proximity: -5.0000e-01\n",
            "Epoch 86/400\n",
            " - 0s - loss: 0.7672 - cosine_proximity: -5.0000e-01\n",
            "Epoch 87/400\n",
            " - 0s - loss: 0.7668 - cosine_proximity: -5.0000e-01\n",
            "Epoch 88/400\n",
            " - 0s - loss: 0.7664 - cosine_proximity: -5.0000e-01\n",
            "Epoch 89/400\n",
            " - 0s - loss: 0.7660 - cosine_proximity: -5.0000e-01\n",
            "Epoch 90/400\n",
            " - 0s - loss: 0.7656 - cosine_proximity: -5.0000e-01\n",
            "Epoch 91/400\n",
            " - 0s - loss: 0.7653 - cosine_proximity: -5.0000e-01\n",
            "Epoch 92/400\n",
            " - 0s - loss: 0.7649 - cosine_proximity: -5.0000e-01\n",
            "Epoch 93/400\n",
            " - 0s - loss: 0.7645 - cosine_proximity: -5.0000e-01\n",
            "Epoch 94/400\n",
            " - 0s - loss: 0.7641 - cosine_proximity: -5.0000e-01\n",
            "Epoch 95/400\n",
            " - 0s - loss: 0.7637 - cosine_proximity: -5.0000e-01\n",
            "Epoch 96/400\n",
            " - 0s - loss: 0.7634 - cosine_proximity: -5.0000e-01\n",
            "Epoch 97/400\n",
            " - 0s - loss: 0.7630 - cosine_proximity: -5.0000e-01\n",
            "Epoch 98/400\n",
            " - 0s - loss: 0.7626 - cosine_proximity: -5.0000e-01\n",
            "Epoch 99/400\n",
            " - 0s - loss: 0.7623 - cosine_proximity: -5.0000e-01\n",
            "Epoch 100/400\n",
            " - 0s - loss: 0.7619 - cosine_proximity: -5.0000e-01\n",
            "Epoch 101/400\n",
            " - 0s - loss: 0.7615 - cosine_proximity: -5.0000e-01\n",
            "Epoch 102/400\n",
            " - 0s - loss: 0.7612 - cosine_proximity: -5.0000e-01\n",
            "Epoch 103/400\n",
            " - 0s - loss: 0.7608 - cosine_proximity: -5.0000e-01\n",
            "Epoch 104/400\n",
            " - 0s - loss: 0.7605 - cosine_proximity: -5.0000e-01\n",
            "Epoch 105/400\n",
            " - 0s - loss: 0.7601 - cosine_proximity: -5.0000e-01\n",
            "Epoch 106/400\n",
            " - 0s - loss: 0.7598 - cosine_proximity: -5.0000e-01\n",
            "Epoch 107/400\n",
            " - 0s - loss: 0.7594 - cosine_proximity: -5.0000e-01\n",
            "Epoch 108/400\n",
            " - 0s - loss: 0.7591 - cosine_proximity: -5.0000e-01\n",
            "Epoch 109/400\n",
            " - 0s - loss: 0.7587 - cosine_proximity: -5.0000e-01\n",
            "Epoch 110/400\n",
            " - 0s - loss: 0.7584 - cosine_proximity: -5.0000e-01\n",
            "Epoch 111/400\n",
            " - 0s - loss: 0.7581 - cosine_proximity: -5.0000e-01\n",
            "Epoch 112/400\n",
            " - 0s - loss: 0.7577 - cosine_proximity: -5.0000e-01\n",
            "Epoch 113/400\n",
            " - 0s - loss: 0.7574 - cosine_proximity: -5.0000e-01\n",
            "Epoch 114/400\n",
            " - 0s - loss: 0.7570 - cosine_proximity: -5.0000e-01\n",
            "Epoch 115/400\n",
            " - 0s - loss: 0.7567 - cosine_proximity: -5.0000e-01\n",
            "Epoch 116/400\n",
            " - 0s - loss: 0.7564 - cosine_proximity: -5.0000e-01\n",
            "Epoch 117/400\n",
            " - 0s - loss: 0.7560 - cosine_proximity: -5.0000e-01\n",
            "Epoch 118/400\n",
            " - 0s - loss: 0.7557 - cosine_proximity: -5.0000e-01\n",
            "Epoch 119/400\n",
            " - 0s - loss: 0.7554 - cosine_proximity: -5.0000e-01\n",
            "Epoch 120/400\n",
            " - 0s - loss: 0.7551 - cosine_proximity: -5.0000e-01\n",
            "Epoch 121/400\n",
            " - 0s - loss: 0.7547 - cosine_proximity: -5.0000e-01\n",
            "Epoch 122/400\n",
            " - 0s - loss: 0.7544 - cosine_proximity: -5.0000e-01\n",
            "Epoch 123/400\n",
            " - 0s - loss: 0.7541 - cosine_proximity: -5.0000e-01\n",
            "Epoch 124/400\n",
            " - 0s - loss: 0.7538 - cosine_proximity: -5.0000e-01\n",
            "Epoch 125/400\n",
            " - 0s - loss: 0.7534 - cosine_proximity: -5.0000e-01\n",
            "Epoch 126/400\n",
            " - 0s - loss: 0.7531 - cosine_proximity: -5.0000e-01\n",
            "Epoch 127/400\n",
            " - 0s - loss: 0.7528 - cosine_proximity: -5.0000e-01\n",
            "Epoch 128/400\n",
            " - 0s - loss: 0.7525 - cosine_proximity: -5.0000e-01\n",
            "Epoch 129/400\n",
            " - 0s - loss: 0.7522 - cosine_proximity: -5.0000e-01\n",
            "Epoch 130/400\n",
            " - 0s - loss: 0.7519 - cosine_proximity: -5.0000e-01\n",
            "Epoch 131/400\n",
            " - 0s - loss: 0.7516 - cosine_proximity: -5.0000e-01\n",
            "Epoch 132/400\n",
            " - 0s - loss: 0.7512 - cosine_proximity: -5.0000e-01\n",
            "Epoch 133/400\n",
            " - 0s - loss: 0.7509 - cosine_proximity: -5.0000e-01\n",
            "Epoch 134/400\n",
            " - 0s - loss: 0.7506 - cosine_proximity: -5.0000e-01\n",
            "Epoch 135/400\n",
            " - 0s - loss: 0.7503 - cosine_proximity: -5.0000e-01\n",
            "Epoch 136/400\n",
            " - 0s - loss: 0.7500 - cosine_proximity: -5.0000e-01\n",
            "Epoch 137/400\n",
            " - 0s - loss: 0.7497 - cosine_proximity: -5.0000e-01\n",
            "Epoch 138/400\n",
            " - 0s - loss: 0.7494 - cosine_proximity: -5.0000e-01\n",
            "Epoch 139/400\n",
            " - 0s - loss: 0.7491 - cosine_proximity: -5.0000e-01\n",
            "Epoch 140/400\n",
            " - 0s - loss: 0.7488 - cosine_proximity: -5.0000e-01\n",
            "Epoch 141/400\n",
            " - 0s - loss: 0.7485 - cosine_proximity: -5.0000e-01\n",
            "Epoch 142/400\n",
            " - 0s - loss: 0.7482 - cosine_proximity: -5.0000e-01\n",
            "Epoch 143/400\n",
            " - 0s - loss: 0.7479 - cosine_proximity: -5.0000e-01\n",
            "Epoch 144/400\n",
            " - 0s - loss: 0.7476 - cosine_proximity: -5.0000e-01\n",
            "Epoch 145/400\n",
            " - 0s - loss: 0.7473 - cosine_proximity: -5.0000e-01\n",
            "Epoch 146/400\n",
            " - 0s - loss: 0.7470 - cosine_proximity: -5.0000e-01\n",
            "Epoch 147/400\n",
            " - 0s - loss: 0.7467 - cosine_proximity: -5.0000e-01\n",
            "Epoch 148/400\n",
            " - 0s - loss: 0.7464 - cosine_proximity: -5.0000e-01\n",
            "Epoch 149/400\n",
            " - 0s - loss: 0.7461 - cosine_proximity: -5.0000e-01\n",
            "Epoch 150/400\n",
            " - 0s - loss: 0.7458 - cosine_proximity: -5.0000e-01\n",
            "Epoch 151/400\n",
            " - 0s - loss: 0.7455 - cosine_proximity: -5.0000e-01\n",
            "Epoch 152/400\n",
            " - 0s - loss: 0.7452 - cosine_proximity: -5.0000e-01\n",
            "Epoch 153/400\n",
            " - 0s - loss: 0.7449 - cosine_proximity: -5.0000e-01\n",
            "Epoch 154/400\n",
            " - 0s - loss: 0.7446 - cosine_proximity: -5.0000e-01\n",
            "Epoch 155/400\n",
            " - 0s - loss: 0.7443 - cosine_proximity: -5.0000e-01\n",
            "Epoch 156/400\n",
            " - 0s - loss: 0.7440 - cosine_proximity: -5.0000e-01\n",
            "Epoch 157/400\n",
            " - 0s - loss: 0.7437 - cosine_proximity: -5.0000e-01\n",
            "Epoch 158/400\n",
            " - 0s - loss: 0.7434 - cosine_proximity: -5.0000e-01\n",
            "Epoch 159/400\n",
            " - 0s - loss: 0.7431 - cosine_proximity: -5.0000e-01\n",
            "Epoch 160/400\n",
            " - 0s - loss: 0.7428 - cosine_proximity: -5.0000e-01\n",
            "Epoch 161/400\n",
            " - 0s - loss: 0.7425 - cosine_proximity: -5.0000e-01\n",
            "Epoch 162/400\n",
            " - 0s - loss: 0.7422 - cosine_proximity: -5.0000e-01\n",
            "Epoch 163/400\n",
            " - 0s - loss: 0.7419 - cosine_proximity: -5.0000e-01\n",
            "Epoch 164/400\n",
            " - 0s - loss: 0.7417 - cosine_proximity: -5.0000e-01\n",
            "Epoch 165/400\n",
            " - 0s - loss: 0.7414 - cosine_proximity: -5.0000e-01\n",
            "Epoch 166/400\n",
            " - 0s - loss: 0.7411 - cosine_proximity: -5.0000e-01\n",
            "Epoch 167/400\n",
            " - 0s - loss: 0.7408 - cosine_proximity: -5.0000e-01\n",
            "Epoch 168/400\n",
            " - 0s - loss: 0.7405 - cosine_proximity: -5.0000e-01\n",
            "Epoch 169/400\n",
            " - 0s - loss: 0.7402 - cosine_proximity: -5.0000e-01\n",
            "Epoch 170/400\n",
            " - 0s - loss: 0.7399 - cosine_proximity: -5.0000e-01\n",
            "Epoch 171/400\n",
            " - 0s - loss: 0.7396 - cosine_proximity: -5.0000e-01\n",
            "Epoch 172/400\n",
            " - 0s - loss: 0.7393 - cosine_proximity: -5.0000e-01\n",
            "Epoch 173/400\n",
            " - 0s - loss: 0.7390 - cosine_proximity: -5.0000e-01\n",
            "Epoch 174/400\n",
            " - 0s - loss: 0.7387 - cosine_proximity: -5.0000e-01\n",
            "Epoch 175/400\n",
            " - 0s - loss: 0.7384 - cosine_proximity: -5.0000e-01\n",
            "Epoch 176/400\n",
            " - 0s - loss: 0.7381 - cosine_proximity: -5.0000e-01\n",
            "Epoch 177/400\n",
            " - 0s - loss: 0.7379 - cosine_proximity: -5.0000e-01\n",
            "Epoch 178/400\n",
            " - 0s - loss: 0.7376 - cosine_proximity: -5.0000e-01\n",
            "Epoch 179/400\n",
            " - 0s - loss: 0.7373 - cosine_proximity: -5.0000e-01\n",
            "Epoch 180/400\n",
            " - 0s - loss: 0.7370 - cosine_proximity: -5.0000e-01\n",
            "Epoch 181/400\n",
            " - 0s - loss: 0.7367 - cosine_proximity: -5.0000e-01\n",
            "Epoch 182/400\n",
            " - 0s - loss: 0.7364 - cosine_proximity: -5.0000e-01\n",
            "Epoch 183/400\n",
            " - 0s - loss: 0.7361 - cosine_proximity: -5.0000e-01\n",
            "Epoch 184/400\n",
            " - 0s - loss: 0.7358 - cosine_proximity: -5.0000e-01\n",
            "Epoch 185/400\n",
            " - 0s - loss: 0.7355 - cosine_proximity: -5.0000e-01\n",
            "Epoch 186/400\n",
            " - 0s - loss: 0.7352 - cosine_proximity: -5.0000e-01\n",
            "Epoch 187/400\n",
            " - 0s - loss: 0.7349 - cosine_proximity: -5.0000e-01\n",
            "Epoch 188/400\n",
            " - 0s - loss: 0.7346 - cosine_proximity: -5.0000e-01\n",
            "Epoch 189/400\n",
            " - 0s - loss: 0.7343 - cosine_proximity: -5.0000e-01\n",
            "Epoch 190/400\n",
            " - 0s - loss: 0.7341 - cosine_proximity: -5.0000e-01\n",
            "Epoch 191/400\n",
            " - 0s - loss: 0.7338 - cosine_proximity: -5.0000e-01\n",
            "Epoch 192/400\n",
            " - 0s - loss: 0.7335 - cosine_proximity: -5.0000e-01\n",
            "Epoch 193/400\n",
            " - 0s - loss: 0.7332 - cosine_proximity: -5.0000e-01\n",
            "Epoch 194/400\n",
            " - 0s - loss: 0.7329 - cosine_proximity: -5.0000e-01\n",
            "Epoch 195/400\n",
            " - 0s - loss: 0.7326 - cosine_proximity: -5.0000e-01\n",
            "Epoch 196/400\n",
            " - 0s - loss: 0.7323 - cosine_proximity: -5.0000e-01\n",
            "Epoch 197/400\n",
            " - 0s - loss: 0.7320 - cosine_proximity: -5.0000e-01\n",
            "Epoch 198/400\n",
            " - 0s - loss: 0.7317 - cosine_proximity: -5.0000e-01\n",
            "Epoch 199/400\n",
            " - 0s - loss: 0.7314 - cosine_proximity: -5.0000e-01\n",
            "Epoch 200/400\n",
            " - 0s - loss: 0.7311 - cosine_proximity: -5.0000e-01\n",
            "Epoch 201/400\n",
            " - 0s - loss: 0.7308 - cosine_proximity: -5.0000e-01\n",
            "Epoch 202/400\n",
            " - 0s - loss: 0.7305 - cosine_proximity: -5.0000e-01\n",
            "Epoch 203/400\n",
            " - 0s - loss: 0.7302 - cosine_proximity: -5.0000e-01\n",
            "Epoch 204/400\n",
            " - 0s - loss: 0.7299 - cosine_proximity: -5.0000e-01\n",
            "Epoch 205/400\n",
            " - 0s - loss: 0.7296 - cosine_proximity: -5.0000e-01\n",
            "Epoch 206/400\n",
            " - 0s - loss: 0.7293 - cosine_proximity: -5.0000e-01\n",
            "Epoch 207/400\n",
            " - 0s - loss: 0.7290 - cosine_proximity: -5.0000e-01\n",
            "Epoch 208/400\n",
            " - 0s - loss: 0.7287 - cosine_proximity: -5.0000e-01\n",
            "Epoch 209/400\n",
            " - 0s - loss: 0.7284 - cosine_proximity: -5.0000e-01\n",
            "Epoch 210/400\n",
            " - 0s - loss: 0.7281 - cosine_proximity: -5.0000e-01\n",
            "Epoch 211/400\n",
            " - 0s - loss: 0.7278 - cosine_proximity: -5.0000e-01\n",
            "Epoch 212/400\n",
            " - 0s - loss: 0.7276 - cosine_proximity: -5.0000e-01\n",
            "Epoch 213/400\n",
            " - 0s - loss: 0.7273 - cosine_proximity: -5.0000e-01\n",
            "Epoch 214/400\n",
            " - 0s - loss: 0.7270 - cosine_proximity: -5.0000e-01\n",
            "Epoch 215/400\n",
            " - 0s - loss: 0.7267 - cosine_proximity: -5.0000e-01\n",
            "Epoch 216/400\n",
            " - 0s - loss: 0.7264 - cosine_proximity: -5.0000e-01\n",
            "Epoch 217/400\n",
            " - 0s - loss: 0.7261 - cosine_proximity: -5.0000e-01\n",
            "Epoch 218/400\n",
            " - 0s - loss: 0.7258 - cosine_proximity: -5.0000e-01\n",
            "Epoch 219/400\n",
            " - 0s - loss: 0.7255 - cosine_proximity: -5.0000e-01\n",
            "Epoch 220/400\n",
            " - 0s - loss: 0.7252 - cosine_proximity: -5.0000e-01\n",
            "Epoch 221/400\n",
            " - 0s - loss: 0.7249 - cosine_proximity: -5.0000e-01\n",
            "Epoch 222/400\n",
            " - 0s - loss: 0.7246 - cosine_proximity: -5.0000e-01\n",
            "Epoch 223/400\n",
            " - 0s - loss: 0.7242 - cosine_proximity: -5.0000e-01\n",
            "Epoch 224/400\n",
            " - 0s - loss: 0.7239 - cosine_proximity: -5.0000e-01\n",
            "Epoch 225/400\n",
            " - 0s - loss: 0.7236 - cosine_proximity: -5.0000e-01\n",
            "Epoch 226/400\n",
            " - 0s - loss: 0.7233 - cosine_proximity: -5.0000e-01\n",
            "Epoch 227/400\n",
            " - 0s - loss: 0.7230 - cosine_proximity: -5.0000e-01\n",
            "Epoch 228/400\n",
            " - 0s - loss: 0.7227 - cosine_proximity: -5.0000e-01\n",
            "Epoch 229/400\n",
            " - 0s - loss: 0.7224 - cosine_proximity: -5.0000e-01\n",
            "Epoch 230/400\n",
            " - 0s - loss: 0.7221 - cosine_proximity: -5.0000e-01\n",
            "Epoch 231/400\n",
            " - 0s - loss: 0.7218 - cosine_proximity: -5.0000e-01\n",
            "Epoch 232/400\n",
            " - 0s - loss: 0.7215 - cosine_proximity: -5.0000e-01\n",
            "Epoch 233/400\n",
            " - 0s - loss: 0.7212 - cosine_proximity: -5.0000e-01\n",
            "Epoch 234/400\n",
            " - 0s - loss: 0.7209 - cosine_proximity: -5.0000e-01\n",
            "Epoch 235/400\n",
            " - 0s - loss: 0.7206 - cosine_proximity: -5.0000e-01\n",
            "Epoch 236/400\n",
            " - 0s - loss: 0.7203 - cosine_proximity: -5.0000e-01\n",
            "Epoch 237/400\n",
            " - 0s - loss: 0.7200 - cosine_proximity: -5.0000e-01\n",
            "Epoch 238/400\n",
            " - 0s - loss: 0.7197 - cosine_proximity: -5.0000e-01\n",
            "Epoch 239/400\n",
            " - 0s - loss: 0.7194 - cosine_proximity: -5.0000e-01\n",
            "Epoch 240/400\n",
            " - 0s - loss: 0.7191 - cosine_proximity: -5.0000e-01\n",
            "Epoch 241/400\n",
            " - 0s - loss: 0.7188 - cosine_proximity: -5.0000e-01\n",
            "Epoch 242/400\n",
            " - 0s - loss: 0.7185 - cosine_proximity: -5.0000e-01\n",
            "Epoch 243/400\n",
            " - 0s - loss: 0.7181 - cosine_proximity: -5.0000e-01\n",
            "Epoch 244/400\n",
            " - 0s - loss: 0.7178 - cosine_proximity: -5.0000e-01\n",
            "Epoch 245/400\n",
            " - 0s - loss: 0.7175 - cosine_proximity: -5.0000e-01\n",
            "Epoch 246/400\n",
            " - 0s - loss: 0.7172 - cosine_proximity: -5.0000e-01\n",
            "Epoch 247/400\n",
            " - 0s - loss: 0.7169 - cosine_proximity: -5.0000e-01\n",
            "Epoch 248/400\n",
            " - 0s - loss: 0.7166 - cosine_proximity: -5.0000e-01\n",
            "Epoch 249/400\n",
            " - 0s - loss: 0.7163 - cosine_proximity: -5.0000e-01\n",
            "Epoch 250/400\n",
            " - 0s - loss: 0.7160 - cosine_proximity: -5.0000e-01\n",
            "Epoch 251/400\n",
            " - 0s - loss: 0.7157 - cosine_proximity: -5.0000e-01\n",
            "Epoch 252/400\n",
            " - 0s - loss: 0.7154 - cosine_proximity: -5.0000e-01\n",
            "Epoch 253/400\n",
            " - 0s - loss: 0.7150 - cosine_proximity: -5.0000e-01\n",
            "Epoch 254/400\n",
            " - 0s - loss: 0.7147 - cosine_proximity: -5.0000e-01\n",
            "Epoch 255/400\n",
            " - 0s - loss: 0.7144 - cosine_proximity: -5.0000e-01\n",
            "Epoch 256/400\n",
            " - 0s - loss: 0.7141 - cosine_proximity: -5.0000e-01\n",
            "Epoch 257/400\n",
            " - 0s - loss: 0.7138 - cosine_proximity: -5.0000e-01\n",
            "Epoch 258/400\n",
            " - 0s - loss: 0.7135 - cosine_proximity: -5.0000e-01\n",
            "Epoch 259/400\n",
            " - 0s - loss: 0.7132 - cosine_proximity: -5.0000e-01\n",
            "Epoch 260/400\n",
            " - 0s - loss: 0.7128 - cosine_proximity: -5.0000e-01\n",
            "Epoch 261/400\n",
            " - 0s - loss: 0.7125 - cosine_proximity: -5.0000e-01\n",
            "Epoch 262/400\n",
            " - 0s - loss: 0.7122 - cosine_proximity: -5.0000e-01\n",
            "Epoch 263/400\n",
            " - 0s - loss: 0.7119 - cosine_proximity: -5.0000e-01\n",
            "Epoch 264/400\n",
            " - 0s - loss: 0.7116 - cosine_proximity: -5.0000e-01\n",
            "Epoch 265/400\n",
            " - 0s - loss: 0.7113 - cosine_proximity: -5.0000e-01\n",
            "Epoch 266/400\n",
            " - 0s - loss: 0.7110 - cosine_proximity: -5.0000e-01\n",
            "Epoch 267/400\n",
            " - 0s - loss: 0.7106 - cosine_proximity: -5.0000e-01\n",
            "Epoch 268/400\n",
            " - 0s - loss: 0.7103 - cosine_proximity: -5.0000e-01\n",
            "Epoch 269/400\n",
            " - 0s - loss: 0.7100 - cosine_proximity: -5.0000e-01\n",
            "Epoch 270/400\n",
            " - 0s - loss: 0.7097 - cosine_proximity: -5.0000e-01\n",
            "Epoch 271/400\n",
            " - 0s - loss: 0.7094 - cosine_proximity: -5.0000e-01\n",
            "Epoch 272/400\n",
            " - 0s - loss: 0.7090 - cosine_proximity: -5.0000e-01\n",
            "Epoch 273/400\n",
            " - 0s - loss: 0.7087 - cosine_proximity: -5.0000e-01\n",
            "Epoch 274/400\n",
            " - 0s - loss: 0.7084 - cosine_proximity: -5.0000e-01\n",
            "Epoch 275/400\n",
            " - 0s - loss: 0.7081 - cosine_proximity: -5.0000e-01\n",
            "Epoch 276/400\n",
            " - 0s - loss: 0.7078 - cosine_proximity: -5.0000e-01\n",
            "Epoch 277/400\n",
            " - 0s - loss: 0.7075 - cosine_proximity: -5.0000e-01\n",
            "Epoch 278/400\n",
            " - 0s - loss: 0.7071 - cosine_proximity: -5.0000e-01\n",
            "Epoch 279/400\n",
            " - 0s - loss: 0.7068 - cosine_proximity: -5.0000e-01\n",
            "Epoch 280/400\n",
            " - 0s - loss: 0.7065 - cosine_proximity: -5.0000e-01\n",
            "Epoch 281/400\n",
            " - 0s - loss: 0.7062 - cosine_proximity: -5.0000e-01\n",
            "Epoch 282/400\n",
            " - 0s - loss: 0.7058 - cosine_proximity: -5.0000e-01\n",
            "Epoch 283/400\n",
            " - 0s - loss: 0.7055 - cosine_proximity: -5.0000e-01\n",
            "Epoch 284/400\n",
            " - 0s - loss: 0.7052 - cosine_proximity: -5.0000e-01\n",
            "Epoch 285/400\n",
            " - 0s - loss: 0.7049 - cosine_proximity: -5.0000e-01\n",
            "Epoch 286/400\n",
            " - 0s - loss: 0.7046 - cosine_proximity: -5.0000e-01\n",
            "Epoch 287/400\n",
            " - 0s - loss: 0.7042 - cosine_proximity: -5.0000e-01\n",
            "Epoch 288/400\n",
            " - 0s - loss: 0.7039 - cosine_proximity: -5.0000e-01\n",
            "Epoch 289/400\n",
            " - 0s - loss: 0.7036 - cosine_proximity: -5.0000e-01\n",
            "Epoch 290/400\n",
            " - 0s - loss: 0.7033 - cosine_proximity: -5.0000e-01\n",
            "Epoch 291/400\n",
            " - 0s - loss: 0.7029 - cosine_proximity: -5.0000e-01\n",
            "Epoch 292/400\n",
            " - 0s - loss: 0.7026 - cosine_proximity: -5.0000e-01\n",
            "Epoch 293/400\n",
            " - 0s - loss: 0.7023 - cosine_proximity: -5.0000e-01\n",
            "Epoch 294/400\n",
            " - 0s - loss: 0.7020 - cosine_proximity: -5.0000e-01\n",
            "Epoch 295/400\n",
            " - 0s - loss: 0.7016 - cosine_proximity: -5.0000e-01\n",
            "Epoch 296/400\n",
            " - 0s - loss: 0.7013 - cosine_proximity: -5.0000e-01\n",
            "Epoch 297/400\n",
            " - 0s - loss: 0.7010 - cosine_proximity: -5.0000e-01\n",
            "Epoch 298/400\n",
            " - 0s - loss: 0.7007 - cosine_proximity: -5.0000e-01\n",
            "Epoch 299/400\n",
            " - 0s - loss: 0.7003 - cosine_proximity: -5.0000e-01\n",
            "Epoch 300/400\n",
            " - 0s - loss: 0.7000 - cosine_proximity: -5.0000e-01\n",
            "Epoch 301/400\n",
            " - 0s - loss: 0.6997 - cosine_proximity: -5.0000e-01\n",
            "Epoch 302/400\n",
            " - 0s - loss: 0.6993 - cosine_proximity: -5.0000e-01\n",
            "Epoch 303/400\n",
            " - 0s - loss: 0.6990 - cosine_proximity: -5.0000e-01\n",
            "Epoch 304/400\n",
            " - 0s - loss: 0.6987 - cosine_proximity: -5.0000e-01\n",
            "Epoch 305/400\n",
            " - 0s - loss: 0.6984 - cosine_proximity: -5.0000e-01\n",
            "Epoch 306/400\n",
            " - 0s - loss: 0.6980 - cosine_proximity: -5.0000e-01\n",
            "Epoch 307/400\n",
            " - 0s - loss: 0.6977 - cosine_proximity: -5.0000e-01\n",
            "Epoch 308/400\n",
            " - 0s - loss: 0.6974 - cosine_proximity: -5.0000e-01\n",
            "Epoch 309/400\n",
            " - 0s - loss: 0.6970 - cosine_proximity: -5.0000e-01\n",
            "Epoch 310/400\n",
            " - 0s - loss: 0.6967 - cosine_proximity: -5.0000e-01\n",
            "Epoch 311/400\n",
            " - 0s - loss: 0.6964 - cosine_proximity: -5.0000e-01\n",
            "Epoch 312/400\n",
            " - 0s - loss: 0.6961 - cosine_proximity: -5.0000e-01\n",
            "Epoch 313/400\n",
            " - 0s - loss: 0.6957 - cosine_proximity: -5.0000e-01\n",
            "Epoch 314/400\n",
            " - 0s - loss: 0.6954 - cosine_proximity: -5.0000e-01\n",
            "Epoch 315/400\n",
            " - 0s - loss: 0.6951 - cosine_proximity: -5.0000e-01\n",
            "Epoch 316/400\n",
            " - 0s - loss: 0.6947 - cosine_proximity: -5.0000e-01\n",
            "Epoch 317/400\n",
            " - 0s - loss: 0.6944 - cosine_proximity: -5.0000e-01\n",
            "Epoch 318/400\n",
            " - 0s - loss: 0.6941 - cosine_proximity: -5.0000e-01\n",
            "Epoch 319/400\n",
            " - 0s - loss: 0.6937 - cosine_proximity: -5.0000e-01\n",
            "Epoch 320/400\n",
            " - 0s - loss: 0.6934 - cosine_proximity: -5.0000e-01\n",
            "Epoch 321/400\n",
            " - 0s - loss: 0.6931 - cosine_proximity: -5.0000e-01\n",
            "Epoch 322/400\n",
            " - 0s - loss: 0.6927 - cosine_proximity: -5.0000e-01\n",
            "Epoch 323/400\n",
            " - 0s - loss: 0.6924 - cosine_proximity: -5.0000e-01\n",
            "Epoch 324/400\n",
            " - 0s - loss: 0.6921 - cosine_proximity: -5.0000e-01\n",
            "Epoch 325/400\n",
            " - 0s - loss: 0.6917 - cosine_proximity: -5.0000e-01\n",
            "Epoch 326/400\n",
            " - 0s - loss: 0.6914 - cosine_proximity: -5.0000e-01\n",
            "Epoch 327/400\n",
            " - 0s - loss: 0.6911 - cosine_proximity: -5.0000e-01\n",
            "Epoch 328/400\n",
            " - 0s - loss: 0.6907 - cosine_proximity: -5.0000e-01\n",
            "Epoch 329/400\n",
            " - 0s - loss: 0.6904 - cosine_proximity: -5.0000e-01\n",
            "Epoch 330/400\n",
            " - 0s - loss: 0.6901 - cosine_proximity: -5.0000e-01\n",
            "Epoch 331/400\n",
            " - 0s - loss: 0.6897 - cosine_proximity: -5.0000e-01\n",
            "Epoch 332/400\n",
            " - 0s - loss: 0.6894 - cosine_proximity: -5.0000e-01\n",
            "Epoch 333/400\n",
            " - 0s - loss: 0.6890 - cosine_proximity: -5.0000e-01\n",
            "Epoch 334/400\n",
            " - 0s - loss: 0.6887 - cosine_proximity: -5.0000e-01\n",
            "Epoch 335/400\n",
            " - 0s - loss: 0.6884 - cosine_proximity: -5.0000e-01\n",
            "Epoch 336/400\n",
            " - 0s - loss: 0.6880 - cosine_proximity: -5.0000e-01\n",
            "Epoch 337/400\n",
            " - 0s - loss: 0.6877 - cosine_proximity: -5.0000e-01\n",
            "Epoch 338/400\n",
            " - 0s - loss: 0.6874 - cosine_proximity: -5.0000e-01\n",
            "Epoch 339/400\n",
            " - 0s - loss: 0.6870 - cosine_proximity: -5.0000e-01\n",
            "Epoch 340/400\n",
            " - 0s - loss: 0.6867 - cosine_proximity: -5.0000e-01\n",
            "Epoch 341/400\n",
            " - 0s - loss: 0.6863 - cosine_proximity: -5.0000e-01\n",
            "Epoch 342/400\n",
            " - 0s - loss: 0.6860 - cosine_proximity: -5.0000e-01\n",
            "Epoch 343/400\n",
            " - 0s - loss: 0.6857 - cosine_proximity: -5.0000e-01\n",
            "Epoch 344/400\n",
            " - 0s - loss: 0.6853 - cosine_proximity: -5.0000e-01\n",
            "Epoch 345/400\n",
            " - 0s - loss: 0.6850 - cosine_proximity: -5.0000e-01\n",
            "Epoch 346/400\n",
            " - 0s - loss: 0.6846 - cosine_proximity: -5.0000e-01\n",
            "Epoch 347/400\n",
            " - 0s - loss: 0.6843 - cosine_proximity: -5.0000e-01\n",
            "Epoch 348/400\n",
            " - 0s - loss: 0.6840 - cosine_proximity: -5.0000e-01\n",
            "Epoch 349/400\n",
            " - 0s - loss: 0.6836 - cosine_proximity: -5.0000e-01\n",
            "Epoch 350/400\n",
            " - 0s - loss: 0.6833 - cosine_proximity: -5.0000e-01\n",
            "Epoch 351/400\n",
            " - 0s - loss: 0.6829 - cosine_proximity: -5.0000e-01\n",
            "Epoch 352/400\n",
            " - 0s - loss: 0.6826 - cosine_proximity: -5.0000e-01\n",
            "Epoch 353/400\n",
            " - 0s - loss: 0.6823 - cosine_proximity: -5.0000e-01\n",
            "Epoch 354/400\n",
            " - 0s - loss: 0.6819 - cosine_proximity: -5.0000e-01\n",
            "Epoch 355/400\n",
            " - 0s - loss: 0.6816 - cosine_proximity: -5.0000e-01\n",
            "Epoch 356/400\n",
            " - 0s - loss: 0.6812 - cosine_proximity: -5.0000e-01\n",
            "Epoch 357/400\n",
            " - 0s - loss: 0.6809 - cosine_proximity: -5.0000e-01\n",
            "Epoch 358/400\n",
            " - 0s - loss: 0.6806 - cosine_proximity: -5.0000e-01\n",
            "Epoch 359/400\n",
            " - 0s - loss: 0.6802 - cosine_proximity: -5.0000e-01\n",
            "Epoch 360/400\n",
            " - 0s - loss: 0.6799 - cosine_proximity: -5.0000e-01\n",
            "Epoch 361/400\n",
            " - 0s - loss: 0.6795 - cosine_proximity: -5.0000e-01\n",
            "Epoch 362/400\n",
            " - 0s - loss: 0.6792 - cosine_proximity: -5.0000e-01\n",
            "Epoch 363/400\n",
            " - 0s - loss: 0.6788 - cosine_proximity: -5.0000e-01\n",
            "Epoch 364/400\n",
            " - 0s - loss: 0.6785 - cosine_proximity: -5.0000e-01\n",
            "Epoch 365/400\n",
            " - 0s - loss: 0.6781 - cosine_proximity: -5.0000e-01\n",
            "Epoch 366/400\n",
            " - 0s - loss: 0.6778 - cosine_proximity: -5.0000e-01\n",
            "Epoch 367/400\n",
            " - 0s - loss: 0.6775 - cosine_proximity: -5.0000e-01\n",
            "Epoch 368/400\n",
            " - 0s - loss: 0.6771 - cosine_proximity: -5.0000e-01\n",
            "Epoch 369/400\n",
            " - 0s - loss: 0.6768 - cosine_proximity: -5.0000e-01\n",
            "Epoch 370/400\n",
            " - 0s - loss: 0.6764 - cosine_proximity: -5.0000e-01\n",
            "Epoch 371/400\n",
            " - 0s - loss: 0.6761 - cosine_proximity: -5.0000e-01\n",
            "Epoch 372/400\n",
            " - 0s - loss: 0.6757 - cosine_proximity: -5.0000e-01\n",
            "Epoch 373/400\n",
            " - 0s - loss: 0.6754 - cosine_proximity: -5.0000e-01\n",
            "Epoch 374/400\n",
            " - 0s - loss: 0.6750 - cosine_proximity: -5.0000e-01\n",
            "Epoch 375/400\n",
            " - 0s - loss: 0.6747 - cosine_proximity: -5.0000e-01\n",
            "Epoch 376/400\n",
            " - 0s - loss: 0.6743 - cosine_proximity: -5.0000e-01\n",
            "Epoch 377/400\n",
            " - 0s - loss: 0.6740 - cosine_proximity: -5.0000e-01\n",
            "Epoch 378/400\n",
            " - 0s - loss: 0.6737 - cosine_proximity: -5.0000e-01\n",
            "Epoch 379/400\n",
            " - 0s - loss: 0.6733 - cosine_proximity: -5.0000e-01\n",
            "Epoch 380/400\n",
            " - 0s - loss: 0.6730 - cosine_proximity: -5.0000e-01\n",
            "Epoch 381/400\n",
            " - 0s - loss: 0.6726 - cosine_proximity: -5.0000e-01\n",
            "Epoch 382/400\n",
            " - 0s - loss: 0.6723 - cosine_proximity: -5.0000e-01\n",
            "Epoch 383/400\n",
            " - 0s - loss: 0.6719 - cosine_proximity: -5.0000e-01\n",
            "Epoch 384/400\n",
            " - 0s - loss: 0.6716 - cosine_proximity: -5.0000e-01\n",
            "Epoch 385/400\n",
            " - 0s - loss: 0.6712 - cosine_proximity: -5.0000e-01\n",
            "Epoch 386/400\n",
            " - 0s - loss: 0.6709 - cosine_proximity: -5.0000e-01\n",
            "Epoch 387/400\n",
            " - 0s - loss: 0.6705 - cosine_proximity: -5.0000e-01\n",
            "Epoch 388/400\n",
            " - 0s - loss: 0.6702 - cosine_proximity: -5.0000e-01\n",
            "Epoch 389/400\n",
            " - 0s - loss: 0.6698 - cosine_proximity: -5.0000e-01\n",
            "Epoch 390/400\n",
            " - 0s - loss: 0.6695 - cosine_proximity: -5.0000e-01\n",
            "Epoch 391/400\n",
            " - 0s - loss: 0.6691 - cosine_proximity: -5.0000e-01\n",
            "Epoch 392/400\n",
            " - 0s - loss: 0.6688 - cosine_proximity: -5.0000e-01\n",
            "Epoch 393/400\n",
            " - 0s - loss: 0.6684 - cosine_proximity: -5.0000e-01\n",
            "Epoch 394/400\n",
            " - 0s - loss: 0.6681 - cosine_proximity: -5.0000e-01\n",
            "Epoch 395/400\n",
            " - 0s - loss: 0.6677 - cosine_proximity: -5.0000e-01\n",
            "Epoch 396/400\n",
            " - 0s - loss: 0.6674 - cosine_proximity: -5.0000e-01\n",
            "Epoch 397/400\n",
            " - 0s - loss: 0.6670 - cosine_proximity: -5.0000e-01\n",
            "Epoch 398/400\n",
            " - 0s - loss: 0.6667 - cosine_proximity: -5.0000e-01\n",
            "Epoch 399/400\n",
            " - 0s - loss: 0.6663 - cosine_proximity: -5.0000e-01\n",
            "Epoch 400/400\n",
            " - 0s - loss: 0.6660 - cosine_proximity: -5.0000e-01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vp_MB0QVEzU",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTYTpK4PFF1A",
        "colab_type": "text"
      },
      "source": [
        "*ACCURACY SCORES*\n",
        "\n",
        "**Accuracy-**\n",
        "\n",
        "Test loss: 0.10376196658944027\n",
        "\n",
        "\n",
        "Test accuracy: 0.9757\n",
        "\n",
        "\n",
        "**binary_accuracy-**\n",
        "\n",
        "Test loss: 0.15646206490577766\n",
        "\n",
        "\n",
        "Test accuracy: 0.9955399974822998\n",
        "\n",
        "\n",
        "**categorical_accuracy-**\n",
        "\n",
        "Test loss: 0.14195446051103405\n",
        "\n",
        "\n",
        "Test accuracy: 0.9816\n",
        "\n",
        "\n",
        "**top_k_categorical_accuracy-**\n",
        "\n",
        "Test loss: 0.15224556388646485\n",
        "\n",
        "\n",
        "Test accuracy: 0.9999\n",
        "\n",
        "\n",
        "**sparse_categorical_accuracy-**\n",
        "\n",
        "loss: 0.4375 \n",
        "\n",
        "\n",
        "sparse_categorical_accuracy: 0.5000\n",
        "\n",
        "\n",
        "**sparse_top_k_categorical_accuracy-**\n",
        "\n",
        "loss: 0.7547 \n",
        "\n",
        "\n",
        "sparse_top_k_categorical_accuracy: 0.5000\n",
        "\n",
        "\n",
        "**cosine_proximity-**\n",
        "\n",
        "loss: 0.7574 \n",
        "\n",
        "\n",
        "cosine_proximity: -5.0000e-01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXtv1hZ7KTzZ",
        "colab_type": "text"
      },
      "source": [
        "The best metric among all is **top_k_categorical_accuracy** which gives almost an accuracy of 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LatctACmMT9Y",
        "colab_type": "code",
        "outputId": "db810982-3180-43cc-b5fa-94e2b32a9fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(Y_train, 10)\n",
        "Y_test =  to_categorical(Y_test, 10)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 3s 51us/step - loss: 3.5652 - top_k_categorical_accuracy: 0.7461 - val_loss: 1.8930 - val_top_k_categorical_accuracy: 0.8295\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.8093 - top_k_categorical_accuracy: 0.8459 - val_loss: 1.8034 - val_top_k_categorical_accuracy: 0.8424\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.7030 - top_k_categorical_accuracy: 0.8738 - val_loss: 1.6407 - val_top_k_categorical_accuracy: 0.8839\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.6297 - top_k_categorical_accuracy: 0.8877 - val_loss: 1.7357 - val_top_k_categorical_accuracy: 0.8706\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 1.5776 - top_k_categorical_accuracy: 0.8974 - val_loss: 1.5338 - val_top_k_categorical_accuracy: 0.9083\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.5313 - top_k_categorical_accuracy: 0.9049 - val_loss: 1.6754 - val_top_k_categorical_accuracy: 0.8852\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.4936 - top_k_categorical_accuracy: 0.9116 - val_loss: 1.5913 - val_top_k_categorical_accuracy: 0.8971\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 1.4653 - top_k_categorical_accuracy: 0.9161 - val_loss: 1.4921 - val_top_k_categorical_accuracy: 0.9108\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 1.4378 - top_k_categorical_accuracy: 0.9204 - val_loss: 1.4968 - val_top_k_categorical_accuracy: 0.9105\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 1.4170 - top_k_categorical_accuracy: 0.9244 - val_loss: 1.5373 - val_top_k_categorical_accuracy: 0.9109\n",
            "Test loss: 1.5372948930740356\n",
            "Test accuracy: 0.9109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eZxoUOWNTpK",
        "colab_type": "text"
      },
      "source": [
        "**CIFAR 10**\n",
        "\n",
        "Test loss: 1.4908046955108643\n",
        "\n",
        "\n",
        "Test accuracy: 0.914"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkNHWHHvNIdL",
        "colab_type": "code",
        "outputId": "a53c747e-7de8-412c-8b69-667807722f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(Y_train, 100)\n",
        "Y_test =  to_categorical(Y_test, 100)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 3s 54us/step - loss: 4.2813 - top_k_categorical_accuracy: 0.2046 - val_loss: 3.9339 - val_top_k_categorical_accuracy: 0.2902\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 3.7835 - top_k_categorical_accuracy: 0.3391 - val_loss: 3.6975 - val_top_k_categorical_accuracy: 0.3692\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 2s 40us/step - loss: 3.5984 - top_k_categorical_accuracy: 0.3944 - val_loss: 3.8066 - val_top_k_categorical_accuracy: 0.3652\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 3.4606 - top_k_categorical_accuracy: 0.4330 - val_loss: 3.4495 - val_top_k_categorical_accuracy: 0.4472\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 3.3541 - top_k_categorical_accuracy: 0.4608 - val_loss: 3.5586 - val_top_k_categorical_accuracy: 0.4194\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 2s 43us/step - loss: 3.2718 - top_k_categorical_accuracy: 0.4840 - val_loss: 3.5757 - val_top_k_categorical_accuracy: 0.4225\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 2s 41us/step - loss: 3.1992 - top_k_categorical_accuracy: 0.5029 - val_loss: 3.5861 - val_top_k_categorical_accuracy: 0.4211\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 2s 42us/step - loss: 3.1399 - top_k_categorical_accuracy: 0.5186 - val_loss: 3.4101 - val_top_k_categorical_accuracy: 0.4627\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 3.0798 - top_k_categorical_accuracy: 0.5332 - val_loss: 3.3509 - val_top_k_categorical_accuracy: 0.4922\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 2s 44us/step - loss: 3.0223 - top_k_categorical_accuracy: 0.5437 - val_loss: 3.4006 - val_top_k_categorical_accuracy: 0.4739\n",
            "Test loss: 3.4005870738983153\n",
            "Test accuracy: 0.4739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-5z-Rk_NjXe",
        "colab_type": "text"
      },
      "source": [
        "**CIFAR 100**\n",
        "\n",
        "Test loss: 3.393477967834473\n",
        "\n",
        "\n",
        "Test accuracy: 0.483"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbtFF2pVMg1F",
        "colab_type": "code",
        "outputId": "629acc12-e94a-4e33-9b45-b81039561555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "Y_train = to_categorical(Y_train, NUM_CLASSES)\n",
        "Y_test = to_categorical(Y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 5us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.5412 - top_k_categorical_accuracy: 0.9932 - val_loss: 0.4395 - val_top_k_categorical_accuracy: 0.9971\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.3751 - top_k_categorical_accuracy: 0.9978 - val_loss: 0.3806 - val_top_k_categorical_accuracy: 0.9973\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.3337 - top_k_categorical_accuracy: 0.9983 - val_loss: 0.3895 - val_top_k_categorical_accuracy: 0.9972\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.3094 - top_k_categorical_accuracy: 0.9988 - val_loss: 0.3517 - val_top_k_categorical_accuracy: 0.9978\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2913 - top_k_categorical_accuracy: 0.9989 - val_loss: 0.3425 - val_top_k_categorical_accuracy: 0.9968\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.2769 - top_k_categorical_accuracy: 0.9992 - val_loss: 0.4118 - val_top_k_categorical_accuracy: 0.9978\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.2673 - top_k_categorical_accuracy: 0.9991 - val_loss: 0.3907 - val_top_k_categorical_accuracy: 0.9980\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.2564 - top_k_categorical_accuracy: 0.9993 - val_loss: 0.3750 - val_top_k_categorical_accuracy: 0.9985\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.2464 - top_k_categorical_accuracy: 0.9995 - val_loss: 0.3794 - val_top_k_categorical_accuracy: 0.9977\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.2415 - top_k_categorical_accuracy: 0.9995 - val_loss: 0.3717 - val_top_k_categorical_accuracy: 0.9978\n",
            "Test loss: 0.3716743408560753\n",
            "Test accuracy: 0.9978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT_Hk41eNa3K",
        "colab_type": "text"
      },
      "source": [
        "**FASHION_MNIST**\n",
        "\n",
        "Test loss: 0.34572943717837334\n",
        "\n",
        "\n",
        "Test accuracy: 0.9981"
      ]
    }
  ]
}